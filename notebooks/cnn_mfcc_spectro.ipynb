{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22319221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import process_time as ptime\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab13f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss\n",
    "from torch.nn import Sequential, Conv2d, MaxPool2d, Module\n",
    "from torch.nn import Softmax, BatchNorm2d, Dropout, Flatten\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5710ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg binary\n",
    "ffmpeg = \"/usr/bin/ffmpeg\"\n",
    "\n",
    "# text directory\n",
    "text_dir = \"../data/raw/text\"\n",
    "labels_dir = \"../data/raw/labels\"\n",
    "\n",
    "# labels file\n",
    "labels_file = \"../data/interim/labels/labels.csv\"\n",
    "\n",
    "# audio directories\n",
    "audio_dir = \"../data/raw/audio\"\n",
    "audio_out_dir = \"../data/interim/audio\"\n",
    "audio_features_dir = \"../data/processed/audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a394ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_ratings(labels_dir, split_id_clip = False):\n",
    "    \n",
    "    label_files = glob.glob(f\"{labels_dir}/*.csv\")\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for filename in label_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df_list.append(df)\n",
    "\n",
    "\n",
    "    df_labels = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "    label_cols = ['Input.VIDEO_ID', 'Input.CLIP',\n",
    "              'Answer.anger', 'Answer.disgust',\n",
    "              'Answer.fear', 'Answer.happiness',\n",
    "              'Answer.sadness', 'Answer.surprise',\n",
    "              'Answer.sentiment']\n",
    "\n",
    "    label_new_cols = ['id', 'clip',\n",
    "                      'anger', 'disgust',\n",
    "                      'fear', 'happiness',\n",
    "                      'sadness', 'surprise',\n",
    "                      'sentiment']\n",
    "    df_labels = df_labels[label_cols]\n",
    "    df_labels.columns = label_new_cols\n",
    "\n",
    "    # drop row all nan\n",
    "    isna_idx = \\\n",
    "        df_labels.index[df_labels[df_labels.columns[2:]].isna().all(axis=1)]\n",
    "    df_labels.drop(index=isna_idx, inplace=True)\n",
    "    # replace remaining nan's with 0\n",
    "    df_labels = df_labels.replace({np.nan : 0})\n",
    "    # convert ratings to int\n",
    "    df_labels[label_new_cols[2:]] = df_labels[label_new_cols[2:]].astype('Int64')\n",
    "    # set emotions to 0 or 1\n",
    "    df_labels[label_new_cols[2:-1]] = \\\n",
    "        df_labels[label_new_cols[2:-1]].applymap(lambda x : 1 if x > 0 else 0)\n",
    "\n",
    "    # if sentiment > 0 convert to positive = 1, elif < 0 convert to negative = 1\n",
    "    # if none of emotion or sentiment == 1, set none to 1\n",
    "\n",
    "    df_labels['positive'] = \\\n",
    "        df_labels['sentiment'].map(lambda x : 1 if x > 0 else 0)\n",
    "    df_labels['negative'] = \\\n",
    "        df_labels['sentiment'].map(lambda x : 1 if x < 0 else 0)\n",
    "\n",
    "    # drop sentiment column (now in positive/negative)\n",
    "    df_labels.drop(columns='sentiment', inplace=True)\n",
    "    \n",
    "    df_labels['none'] = 0\n",
    "    none_idx = \\\n",
    "        df_labels[df_labels[df_labels.columns[2:]].sum(axis=1) == 0].index\n",
    "\n",
    "    df_labels.loc[none_idx,'none'] = 1\n",
    "\n",
    "    label_new_cols = ['id', 'clip',\n",
    "                      'anger', 'disgust',\n",
    "                      'fear', 'happiness',\n",
    "                      'sadness', 'surprise',\n",
    "                      'sentiment']\n",
    "    # df_labels = \\\n",
    "        # df_labels.\n",
    "    \n",
    "    # remove '/' from id's\n",
    "    df_labels['id'] = df_labels['id'].map(lambda x : str(x).split(\"/\")[-1])\n",
    "    if not split_id_clip:\n",
    "        df_labels['id'] = df_labels['id'] + '_' + df_labels['clip'].astype(str)\n",
    "        df_labels.drop(columns = 'clip', inplace = True)\n",
    "        \n",
    "        label_new_cols = ['id',\n",
    "                          'none', 'positive', 'negative',\n",
    "                          'anger', 'disgust',\n",
    "                          'fear', 'happiness',\n",
    "                          'sadness', 'surprise'\n",
    "                         ]\n",
    "    else:\n",
    "        label_new_cols = ['id', 'clip',\n",
    "                          'none', 'positive', 'negative',\n",
    "                          'anger', 'disgust',\n",
    "                          'fear', 'happiness',\n",
    "                          'sadness', 'surprise'\n",
    "                         ]\n",
    "        \n",
    "    df_labels = df_labels[label_new_cols]\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a3d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_all_rated_clips_ids(labels_dir):\n",
    "#    ratings = load_all_ratings(labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969bf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_ratings(ratings):\n",
    "    '''\n",
    "        aggregate labels to 1 if 2+ ratings of 3 aggree\n",
    "    '''\n",
    "    grp_labels = ratings.groupby('id').sum()\n",
    "    display(grp_labels.head(5))\n",
    "    grp_labels = grp_labels.applymap(lambda x : 1 if x > 1 else 0)\n",
    "    display(grp_labels.head(5))\n",
    "    # drop rows where all == 0\n",
    "    idx = grp_labels[grp_labels.sum(axis =1) == 0].index\n",
    "    grp_labels.drop(index = idx, inplace=True)\n",
    "    print(f\"{len(idx)} rows dropped\")\n",
    "    print(f\"{grp_labels.shape[0]} grouped labels\")\n",
    "    return grp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14ce17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93232ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60d738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78e3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mfcc_spectro(audio_file, len_secs = 2,\n",
    "                     fmax=8000, hop_len = 1024, end_pad_secs=0.1):\n",
    "    full_samples, srate = \\\n",
    "        librosa.load(audio_file, sr=None)\n",
    "    # standardize\n",
    "    # full_samples = (full_samples - full_samples.mean()) / full_samples.std()\n",
    "    \n",
    "    num_samples = srate * len_secs\n",
    "    end_pad = int(srate * end_pad_secs)\n",
    "    \n",
    "    if len(full_samples) < num_samples:\n",
    "        zero_pad = np.zeros(num_samples - len(full_samples))\n",
    "        samples = np.concatenate((zero_pad, full_samples), axis=0)\n",
    "    elif len(full_samples) > num_samples + end_pad:\n",
    "        samples = full_samples[len(full_samples) - num_samples - end_pad:-end_pad]\n",
    "    else:\n",
    "        # print(\"else\")\n",
    "        samples = full_samples[-num_samples:]\n",
    "    # print(len(samples))\n",
    "    S = librosa.feature.melspectrogram(y=samples,\n",
    "                                   sr=srate, n_mels=64, #128,\n",
    "                                   fmax=fmax, hop_length=hop_len)\n",
    "    mfcc_spectro = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=20)#,\n",
    "                                    #hop_length=1024)#, htk=True)\n",
    "    #mfcc_spectro = sklearn.preprocessing.scale(mfcc_spectro, axis=1)\n",
    "    # plt.figure(figsize=(10,8))\n",
    "    # librosa.display.specshow(mfcc_spectro[:, :], sr=test_sr / (hop_len/512),\n",
    "    #                         x_axis='time')\n",
    "    #plt.show()\n",
    "    # print(mfcc_spectro.shape)\n",
    "    return mfcc_spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7ba545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_spectros_from_dir(audio_dir, file_names=None,\n",
    "                                    len_secs=3, show_progress=True):\n",
    "    not_files = []\n",
    "    audio_features = {}\n",
    "    stime = time.time()# ptime()\n",
    "    cnt = 0\n",
    "    if file_names is None:\n",
    "        file_names = glob.glob(f\"{audio_dir}/*.wav\")\n",
    "        # print(file_names[:5])\n",
    "        # file_names = (os.listdir(audio_dir))\n",
    "    else:\n",
    "        file_names = [audio_dir + '/' + f + '.wav' for f in file_names]\n",
    "    num_files = len(file_names) # len(os.listdir(audio_dir))\n",
    "    # for i, f in enumerate(os.listdir(audio_dir)):\n",
    "    mfcc_spectros = []\n",
    "    clip_ids = []\n",
    "    for i, f in enumerate(file_names):\n",
    "        # print(f)\n",
    "        clip_id = f.rsplit('.', maxsplit = 1)[0].rsplit('/', maxsplit = 1)[-1]\n",
    "        # try:\n",
    "        clip_mfcc_spectro = \\\n",
    "                    gen_mfcc_spectro(f, len_secs = len_secs,\n",
    "                                     fmax=8000, hop_len = 1024, #512,\n",
    "                                     end_pad_secs=0.1)\n",
    "        clip_ids.append(clip_id)\n",
    "        mfcc_spectros.append(clip_mfcc_spectro)\n",
    "        #except:\n",
    "        #    print(f\"error : {clip_id}\")\n",
    "        \n",
    "        \n",
    "        if show_progress:\n",
    "            if i % 10 == 0 and i != 0:\n",
    "                print('.', end = '')\n",
    "                if i % 500 == 0:\n",
    "                    print(f\" {i} de {num_files} fichiers\")\n",
    "\n",
    "    mfcc_spectros = np.array(mfcc_spectros)\n",
    "    etime = time.time() # ptime()\n",
    "    proc_time = timedelta(seconds = round(etime - stime))\n",
    "    print(f\"\\n{mfcc_spectros.shape[0]} fichiers extraits: {proc_time} (h:mm:ss)\")\n",
    "    return mfcc_spectros, np.array(clip_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b3a01c",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "090ed179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        n_channels = self.cnn_layers(torch.empty(1, 1, 20, 63)).size(-1)\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(n_channels, 300),\n",
    "            Linear(300, 3)\n",
    "            # Linear(4 * 7 * 7, 10)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaf83bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (1): Linear(in_features=300, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "#if torch.cuda.is_available():\n",
    "#    model = model.cuda()\n",
    "#    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "349dd99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b8fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, Xtrain, ytrain, Xtest, ytest):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    x_train, y_train = Variable(Xtrain), Variable(ytrain)\n",
    "    # x_train, y_train = Xtrain, ytrain\n",
    "    # getting the validation set\n",
    "    x_val, y_val = Variable(Xtest), Variable(ytest)\n",
    "    # x_val, y_val = Xtest, ytest\n",
    "    # converting the data into GPU format\n",
    "    #if torch.cuda.is_available():\n",
    "    #    x_train = x_train.cuda()\n",
    "    #    y_train = y_train.cuda()\n",
    "    #    x_val = x_val.cuda()\n",
    "    #    y_val = y_val.cuda()\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train.float())\n",
    "    output_val = model(x_val.float())\n",
    "\n",
    "    # computing the training and validation loss\n",
    "    loss_train = criterion(output_train, y_train)\n",
    "    loss_val = criterion(output_val, y_val)\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    if epoch%2 == 0:\n",
    "        # printing the validation loss\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bd40ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 \t loss : tensor(1.1178, grad_fn=<NllLossBackward0>)\n",
      "Epoch :  3 \t loss : tensor(124.2669, grad_fn=<NllLossBackward0>)\n",
      "Epoch :  5 \t loss : tensor(104.0745, grad_fn=<NllLossBackward0>)\n",
      "Epoch :  7 \t loss : tensor(35.5201, grad_fn=<NllLossBackward0>)\n",
      "Epoch :  9 \t loss : tensor(25.4375, grad_fn=<NllLossBackward0>)\n",
      "Epoch :  11 \t loss : tensor(10.8557, grad_fn=<NllLossBackward0>)\n",
      "Epoch :  13 \t loss : tensor(8.5423, grad_fn=<NllLossBackward0>)\n",
      "Epoch :  15 \t loss : tensor(4.9201, grad_fn=<NllLossBackward0>)\n",
      "Train time: 0:00:36\n"
     ]
    }
   ],
   "source": [
    "# defining the number of epochs\n",
    "n_epochs = 15\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "val_losses = []\n",
    "\n",
    "stime = time.time()\n",
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch, Xtrain, ytrain, Xtest, ytest)\n",
    "print(f\"Train time: {timedelta(seconds = round(time.time() - stime))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2708081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "with torch.no_grad():\n",
    "    output = model(Variable(Xtrain).float())\n",
    "    \n",
    "softmax = torch.exp(output).cpu()\n",
    "prob = list(softmax.numpy())\n",
    "predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "# accuracy on training set\n",
    "accuracy_score(Variable(ytrain), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2217ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14450, 1, 20, 63])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80733f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6fc2ef3",
   "metadata": {},
   "source": [
    "# Load sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d070e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70764, 10)\n",
      "['id', 'none', 'positive', 'negative', 'anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "all_ratings = load_all_ratings(labels_dir)\n",
    "print(all_ratings.shape)\n",
    "print(all_ratings.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a53525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60743, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_positive = all_ratings['positive'] == 1\n",
    "mask_negative = all_ratings['negative'] == 1\n",
    "mask_none = all_ratings['none'] == 1\n",
    "only_sentiment_ratings = \\\n",
    "    all_ratings[(mask_positive) | (mask_negative) | (mask_none)]\\\n",
    "        [['id','none','positive','negative']].copy()\n",
    "only_sentiment_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef7a8418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>none</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--qXJuDtHPw_5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_10</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                none  positive  negative\n",
       "id                                      \n",
       "--qXJuDtHPw_5      1         2         0\n",
       "-3g5yACwYnA_10     0         2         0\n",
       "-3g5yACwYnA_13     1         2         0\n",
       "-3g5yACwYnA_2      1         0         0\n",
       "-3g5yACwYnA_3      2         0         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>none</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--qXJuDtHPw_5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3g5yACwYnA_3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                none  positive  negative\n",
       "id                                      \n",
       "--qXJuDtHPw_5      0         1         0\n",
       "-3g5yACwYnA_10     0         1         0\n",
       "-3g5yACwYnA_13     0         1         0\n",
       "-3g5yACwYnA_2      0         0         0\n",
       "-3g5yACwYnA_3      1         0         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062 rows dropped\n",
      "18319 grouped labels\n"
     ]
    }
   ],
   "source": [
    "sentiment_labels = aggregate_ratings(only_sentiment_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e61b3813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MPRqaQqrd9Y_7', 'UlTJmndbGHM_4', 'hjBQmIWiWgw_2', '9zWeMrfr-l0_0', '31197_2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_clip_names = glob.glob(f\"{audio_out_dir}/*.wav\")\n",
    "audio_clip_names = \\\n",
    "    [cn.rsplit('.', maxsplit = 1)[0].rsplit('/', maxsplit = 1)[-1] for \\\n",
    "         cn in audio_clip_names]\n",
    "audio_clip_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5625a882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23259\n"
     ]
    }
   ],
   "source": [
    "print(len(audio_clip_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5de22d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_clips_no_audio = []\n",
    "for idx in sentiment_labels.index:\n",
    "    if idx not in audio_clip_names:\n",
    "        labeled_clips_no_audio.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56fa5219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(len(labeled_clips_no_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "446e2996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18063, 3)\n"
     ]
    }
   ],
   "source": [
    "sentiment_labels.drop(index=labeled_clips_no_audio, inplace=True)\n",
    "print(sentiment_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32e568d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................. 500 de 18063 fichiers\n",
      ".................................................. 1000 de 18063 fichiers\n",
      ".................................................. 1500 de 18063 fichiers\n",
      ".................................................. 2000 de 18063 fichiers\n",
      ".................................................. 2500 de 18063 fichiers\n",
      ".................................................. 3000 de 18063 fichiers\n",
      ".................................................. 3500 de 18063 fichiers\n",
      ".................................................. 4000 de 18063 fichiers\n",
      ".................................................. 4500 de 18063 fichiers\n",
      ".................................................. 5000 de 18063 fichiers\n",
      ".................................................. 5500 de 18063 fichiers\n",
      ".................................................. 6000 de 18063 fichiers\n",
      ".................................................. 6500 de 18063 fichiers\n",
      ".................................................. 7000 de 18063 fichiers\n",
      ".................................................. 7500 de 18063 fichiers\n",
      ".................................................. 8000 de 18063 fichiers\n",
      ".................................................. 8500 de 18063 fichiers\n",
      ".................................................. 9000 de 18063 fichiers\n",
      ".................................................. 9500 de 18063 fichiers\n",
      ".................................................. 10000 de 18063 fichiers\n",
      ".................................................. 10500 de 18063 fichiers\n",
      ".................................................. 11000 de 18063 fichiers\n",
      ".................................................. 11500 de 18063 fichiers\n",
      ".................................................. 12000 de 18063 fichiers\n",
      ".................................................. 12500 de 18063 fichiers\n",
      ".................................................. 13000 de 18063 fichiers\n",
      ".................................................. 13500 de 18063 fichiers\n",
      ".................................................. 14000 de 18063 fichiers\n",
      ".................................................. 14500 de 18063 fichiers\n",
      ".................................................. 15000 de 18063 fichiers\n",
      ".................................................. 15500 de 18063 fichiers\n",
      ".................................................. 16000 de 18063 fichiers\n",
      ".................................................. 16500 de 18063 fichiers\n",
      ".................................................. 17000 de 18063 fichiers\n",
      ".................................................. 17500 de 18063 fichiers\n",
      ".................................................. 18000 de 18063 fichiers\n",
      "......\n",
      "18063 fichiers extraits: 0:01:55 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "mfcc_4sec_spec_sent, _ = \\\n",
    "    extract_mfcc_spectros_from_dir(audio_out_dir,\n",
    "                                   file_names=sentiment_labels.index.tolist(),\n",
    "                                    len_secs=4, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d00e907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sentiment_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c08410be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14450, 20, 63)\n",
      "(3613, 20, 63)\n",
      "(14450, 3)\n",
      "(3613, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = \\\n",
    "    train_test_split(mfcc_4sec_spec_sent, labels, test_size=0.2,\n",
    "                     stratify=labels.values.argmax(axis=1))\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aae0b8",
   "metadata": {},
   "source": [
    "# Reshape for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "466d9f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14450, 1, 20, 63])\n",
      "torch.Size([3613, 1, 20, 63])\n",
      "torch.Size([14450])\n",
      "torch.Size([3613])\n"
     ]
    }
   ],
   "source": [
    "Xtrain = \\\n",
    "    Xtrain.reshape(Xtrain.shape[0], 1, Xtrain.shape[1], Xtrain.shape[2]).astype(float)\n",
    "Xtrain = torch.from_numpy(Xtrain)\n",
    "\n",
    "Xtest = \\\n",
    "    Xtest.reshape(Xtest.shape[0], 1, Xtest.shape[1], Xtest.shape[2]).astype(float)\n",
    "Xtest = torch.from_numpy(Xtest)\n",
    "\n",
    "# converting the target into torch format\n",
    "ytrain = ytrain.values.argmax(axis=1).astype(int)\n",
    "ytrain = torch.from_numpy(ytrain)\n",
    "\n",
    "ytest = ytest.values.argmax(axis=1).astype(int)\n",
    "ytest = torch.from_numpy(ytest)\n",
    "\n",
    "\n",
    "# shape of training data\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2fd7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7a2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f218d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

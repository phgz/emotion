{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"../data/raw/text\"\n",
    "labels_dir =  \"../data/raw/labels\"\n",
    "audio_dir = \"../data/raw/audio\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob(f\"{text_dir}/*.txt\")\n",
    "\n",
    "\n",
    "def remove_stamps_str(line)->str:\n",
    "    #clip_num = re.search('.+___\\d\\d?\\d?___.+', line).group(0)\n",
    "    stamp = re.search('.+___', line).group(0)\n",
    "    new_line = line.strip(stamp)\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "bad escape \\d at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\trott\\miniconda3\\lib\\sre_parse.py:1039\u001b[0m, in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1037'>1038</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1038'>1039</a>\u001b[0m     this \u001b[39m=\u001b[39m \u001b[39mchr\u001b[39m(ESCAPES[this][\u001b[39m1\u001b[39m])\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1039'>1040</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\\\d'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32me:\\Projet_emotion\\emotion\\notebooks\\text-model.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projet_emotion/emotion/notebooks/text-model.ipynb#ch0000015?line=0'>1</a>\u001b[0m test_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn-sgVVTE9Io___3___25.613___29.038___So it is very critical to set a budget.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Projet_emotion/emotion/notebooks/text-model.ipynb#ch0000015?line=2'>3</a>\u001b[0m re\u001b[39m.\u001b[39;49msub(\u001b[39m'\u001b[39;49m\u001b[39m___\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39md\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39md?\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39md?___\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39md\u001b[39;49m\u001b[39m'\u001b[39;49m, test_str)\u001b[39m.\u001b[39mgroup(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\trott\\miniconda3\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=202'>203</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=203'>204</a>\u001b[0m     \u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=204'>205</a>\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=205'>206</a>\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=206'>207</a>\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=207'>208</a>\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=208'>209</a>\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=209'>210</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
      "File \u001b[1;32mc:\\Users\\trott\\miniconda3\\lib\\re.py:327\u001b[0m, in \u001b[0;36m_subx\u001b[1;34m(pattern, template)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=324'>325</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_subx\u001b[39m(pattern, template):\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=325'>326</a>\u001b[0m     \u001b[39m# internal: Pattern.sub/subn implementation helper\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=326'>327</a>\u001b[0m     template \u001b[39m=\u001b[39m _compile_repl(template, pattern)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=327'>328</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m template[\u001b[39m0\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(template[\u001b[39m1\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=328'>329</a>\u001b[0m         \u001b[39m# literal replacement\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=329'>330</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m template[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\trott\\miniconda3\\lib\\re.py:318\u001b[0m, in \u001b[0;36m_compile_repl\u001b[1;34m(repl, pattern)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=314'>315</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(_MAXCACHE)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=315'>316</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compile_repl\u001b[39m(repl, pattern):\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=316'>317</a>\u001b[0m     \u001b[39m# internal: compile replacement pattern\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/miniconda3/lib/re.py?line=317'>318</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sre_parse\u001b[39m.\u001b[39;49mparse_template(repl, pattern)\n",
      "File \u001b[1;32mc:\\Users\\trott\\miniconda3\\lib\\sre_parse.py:1042\u001b[0m, in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1039'>1040</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1040'>1041</a>\u001b[0m             \u001b[39mif\u001b[39;00m c \u001b[39min\u001b[39;00m ASCIILETTERS:\n\u001b[1;32m-> <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1041'>1042</a>\u001b[0m                 \u001b[39mraise\u001b[39;00m s\u001b[39m.\u001b[39merror(\u001b[39m'\u001b[39m\u001b[39mbad escape \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m this, \u001b[39mlen\u001b[39m(this))\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1042'>1043</a>\u001b[0m         lappend(this)\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/miniconda3/lib/sre_parse.py?line=1043'>1044</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\d at position 0"
     ]
    }
   ],
   "source": [
    "test_str = \"n-sgVVTE9Io___3___25.613___29.038___So it is very critical to set a budget.\"\n",
    "taco = re.search\n",
    "re.sub('___\\d\\d?\\d?___', '\\d', test_str).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retire chaque stamps, chaque texte devien 1 seul str\n",
    "corpus = []\n",
    "text = []\n",
    "for filename in text_files:\n",
    "    text_str = ''\n",
    "    with open(file=filename, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for count, line in enumerate(lines):\n",
    "            clean_line = remove_stamps_str(line)\n",
    "            text.append(clean_line)\n",
    "    text_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('English')\n",
    "\n",
    "#création d'un dict pour lookup en O(1)\n",
    "stopwords_dict = Counter(stop_words)\n",
    "\n",
    "\n",
    "def avg_count(l1:list):\n",
    "    word_count = 0\n",
    "    for e in l1:\n",
    "        word_count += len(e.split())\n",
    "    return int(word_count/len(l1))\n",
    "\n",
    "#Retire tous les timestamps en début de ligne, présents dans chaque transcript\n",
    "def remove_stamps_str(line)->str:\n",
    "    stamp = re.search('.+___', line).group(0)\n",
    "    new_line = line.strip(stamp)\n",
    "    return new_line\n",
    "\n",
    "#Retire les charactères non-ascii \n",
    "def remove_nonascii(line)->str:\n",
    "    ascii_line = line.encode(encoding = 'ascii', errors = 'ignore').decode()\n",
    "    return ascii_line\n",
    "\n",
    "#met tout en minuscules, retire les nombres et stopwords\n",
    "def clean_stopwords_digits(line)->str:\n",
    "    new_line = ' '.join([word.lower() for word in line.split() if (len(word) >=2 and word.isalpha() and word not in stopwords_dict)])\n",
    "    return new_line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3g5yACwYnA_10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3g5yACwYnA_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3g5yACwYnA_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3g5yACwYnA_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21860</th>\n",
       "      <td>zwTrXwi54us_6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861</th>\n",
       "      <td>zwTrXwi54us_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>zwTrXwi54us_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21863</th>\n",
       "      <td>zwTrXwi54us_9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21864</th>\n",
       "      <td>zx4W0Vuus-I_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21865 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  anger  disgust  fear  happiness  sadness  surprise  \\\n",
       "0       --qXJuDtHPw_5      0        0     0          1        0         0   \n",
       "1      -3g5yACwYnA_10      0        0     0          0        0         0   \n",
       "2      -3g5yACwYnA_13      0        0     0          0        0         0   \n",
       "3       -3g5yACwYnA_2      0        0     0          1        0         0   \n",
       "4       -3g5yACwYnA_3      0        0     0          0        0         0   \n",
       "...               ...    ...      ...   ...        ...      ...       ...   \n",
       "21860   zwTrXwi54us_6      0        0     0          0        0         0   \n",
       "21861   zwTrXwi54us_7      0        0     0          0        0         0   \n",
       "21862   zwTrXwi54us_8      0        0     0          0        0         0   \n",
       "21863   zwTrXwi54us_9      0        0     0          0        0         0   \n",
       "21864   zx4W0Vuus-I_1      0        0     0          1        0         0   \n",
       "\n",
       "       sentiment  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "21860          0  \n",
       "21861          0  \n",
       "21862          0  \n",
       "21863          1  \n",
       "21864          1  \n",
       "\n",
       "[21865 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id_label_df = pd.read_csv(\"../data/interim/labels/interim.csv\")\n",
    "display(id_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### word_tokenize utile? Lent, semble pas nécessaire, peut juste split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>pre_cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lines</th>\n",
       "      <th>avg_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I see that there are three category of writers...</td>\n",
       "      <td>I see that there are three category of writers...</td>\n",
       "      <td>[see, three, category, define, story, an, like...</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi, my name is Raj Shah. I'm from Spectro Coat...</td>\n",
       "      <td>Hi, my name is Raj Shah. I'm from Spectro Coat...</td>\n",
       "      <td>[name, raj, spectro, vice, president, key, pol...</td>\n",
       "      <td>2044</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Introduction Speaker: Dr. Erma Jean Sims, Sono...</td>\n",
       "      <td>Introduction Speaker: Dr. Erma Jean Sims, Sono...</td>\n",
       "      <td>[introduction, erma, jean, sonoma, state, univ...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is Rhett Reiger, White Caspian Studios on...</td>\n",
       "      <td>This is Rhett Reiger, White Caspian Studios on...</td>\n",
       "      <td>[this, rhett, white, caspian, studios, behalf,...</td>\n",
       "      <td>1501</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is financial adviser Patrick Munro answer...</td>\n",
       "      <td>This is financial adviser Patrick Munro answer...</td>\n",
       "      <td>[this, financial, adviser, patrick, munro, ans...</td>\n",
       "      <td>1055</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>Hi Guys I just wanted to share my thoughts wit...</td>\n",
       "      <td>Hi Guys I just wanted to share my thoughts wit...</td>\n",
       "      <td>[hi, guys, wanted, share, thoughts, book, resu...</td>\n",
       "      <td>1117</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>- University of Illinois candidates are very p...</td>\n",
       "      <td>- University of Illinois candidates are very p...</td>\n",
       "      <td>[university, illinois, candidates, prepared, g...</td>\n",
       "      <td>759</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>e use both, again, we use Aprimo software inte...</td>\n",
       "      <td>e use both, again, we use Aprimo software inte...</td>\n",
       "      <td>[use, use, aprimo, software, internally, use, ...</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>Well, I think for us it’s-- the way to leverag...</td>\n",
       "      <td>Well, I think for us its-- the way to leverage...</td>\n",
       "      <td>[think, us, way, leverage, technology, innovat...</td>\n",
       "      <td>1957</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>JOHN GERZEMA: When I think about finding insig...</td>\n",
       "      <td>JOHN GERZEMA: When I think about finding insig...</td>\n",
       "      <td>[john, when, think, finding, insights, think, ...</td>\n",
       "      <td>880</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3837 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_text  \\\n",
       "0     I see that there are three category of writers...   \n",
       "1     Hi, my name is Raj Shah. I'm from Spectro Coat...   \n",
       "2     Introduction Speaker: Dr. Erma Jean Sims, Sono...   \n",
       "3     This is Rhett Reiger, White Caspian Studios on...   \n",
       "4     This is financial adviser Patrick Munro answer...   \n",
       "...                                                 ...   \n",
       "3832  Hi Guys I just wanted to share my thoughts wit...   \n",
       "3833  - University of Illinois candidates are very p...   \n",
       "3834  e use both, again, we use Aprimo software inte...   \n",
       "3835  Well, I think for us it’s-- the way to leverag...   \n",
       "3836  JOHN GERZEMA: When I think about finding insig...   \n",
       "\n",
       "                                       pre_cleaned_text  \\\n",
       "0     I see that there are three category of writers...   \n",
       "1     Hi, my name is Raj Shah. I'm from Spectro Coat...   \n",
       "2     Introduction Speaker: Dr. Erma Jean Sims, Sono...   \n",
       "3     This is Rhett Reiger, White Caspian Studios on...   \n",
       "4     This is financial adviser Patrick Munro answer...   \n",
       "...                                                 ...   \n",
       "3832  Hi Guys I just wanted to share my thoughts wit...   \n",
       "3833  - University of Illinois candidates are very p...   \n",
       "3834  e use both, again, we use Aprimo software inte...   \n",
       "3835  Well, I think for us its-- the way to leverage...   \n",
       "3836  JOHN GERZEMA: When I think about finding insig...   \n",
       "\n",
       "                                                 tokens  lines  avg_count  \\\n",
       "0     [see, three, category, define, story, an, like...    771          0   \n",
       "1     [name, raj, spectro, vice, president, key, pol...   2044          0   \n",
       "2     [introduction, erma, jean, sonoma, state, univ...    650          0   \n",
       "3     [this, rhett, white, caspian, studios, behalf,...   1501          0   \n",
       "4     [this, financial, adviser, patrick, munro, ans...   1055          0   \n",
       "...                                                 ...    ...        ...   \n",
       "3832  [hi, guys, wanted, share, thoughts, book, resu...   1117          0   \n",
       "3833  [university, illinois, candidates, prepared, g...    759          0   \n",
       "3834  [use, use, aprimo, software, internally, use, ...    595          0   \n",
       "3835  [think, us, way, leverage, technology, innovat...   1957          0   \n",
       "3836  [john, when, think, finding, insights, think, ...    880          0   \n",
       "\n",
       "      word_count  \n",
       "0             49  \n",
       "1            144  \n",
       "2             51  \n",
       "3            110  \n",
       "4             80  \n",
       "...          ...  \n",
       "3832         103  \n",
       "3833          43  \n",
       "3834          39  \n",
       "3835         150  \n",
       "3836          70  \n",
       "\n",
       "[3837 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_text = pd.DataFrame((np.array(text_list, dtype= object)).reshape(-1))\n",
    "df_text.columns = ['raw_text']\n",
    "\n",
    "df_text['raw_text'] = df_text['raw_text'].apply(lambda x : ' '.join(x))\n",
    "df_text['pre_cleaned_text'] = df_text['raw_text'].apply(remove_nonascii)\n",
    "\n",
    "#on utilise la librairie NLTK pour sortir que les \"tokens\"\n",
    "\n",
    "\n",
    "\n",
    "df_text['tokens'] = df_text['pre_cleaned_text'].apply(lambda l : word_tokenize(''.join(clean_stopwords_digits(l))))\n",
    "\n",
    "\n",
    "df_text['lines'] = df_text['raw_text'].apply(lambda x : len(x))\n",
    "df_text['avg_count'] = df_text['raw_text'].apply(avg_count)\n",
    "df_text['word_count'] = df_text['tokens'].apply(len)\n",
    "\n",
    "\n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\trott\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "df_text['tagged'] = df_text['tokens'].apply(nltk.tag.pos_tag )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "#SEULEMENT PRENDRE MOT DANS MODEL.VOCAB"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1397d0775792a3058dbf629ef5acb1a668f4b76e78861145d1ae250fb53dcec6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

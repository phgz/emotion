{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "#from tensorflow.keras.models import model_from_json\n",
    "from transformers import BertTokenizerFast, TFBertModel\n",
    "from sklearn.model_selection import train_test_split as tts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"../data/raw/text\"\n",
    "labels_dir =  \"../data/raw/labels\"\n",
    "audio_dir = \"../data/raw/audio\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob(f\"{text_dir}/*.txt\")\n",
    "\n",
    "\n",
    "def remove_stamps_str(line)->str:\n",
    "    #clip_num = re.search('.+___\\d\\d?\\d?___.+', line).group(0)\n",
    "    stamp = re.search('.+___', line).group(0)\n",
    "    new_line = line.strip(stamp)\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncorpus = []\\ntext = []\\ntext_list = []\\nfor filename in text_files:\\n    text_str = ''\\n    with open(file=filename, encoding='utf-8') as f:\\n        lines = f.readlines()\\n        for count, line in enumerate(lines):\\n            clean_line = remove_stamps_str(line)\\n            text.append(clean_line)\\n    text_list.append(text)\\n    \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retire chaque stamps, chaque texte devien 1 seul str\n",
    "\n",
    "def text_list_generator(files_list):\n",
    "    text_list = []\n",
    "    for filename in files_list:\n",
    "        with open(file = filename, encoding = 'utf-8') as f:\n",
    "\n",
    "            ##WINDOWS SPECIFIC\n",
    "            videoid = filename.removeprefix(text_dir + '\\\\').rstrip('.txt')\n",
    "            lines = f.readlines()\n",
    "            for line_number, text_line in enumerate(lines):\n",
    "                clean_line = remove_stamps_str(text_line)\n",
    "                clip_id = videoid +'_' +str(line_number)\n",
    "                yield (clip_id, clean_line.rstrip())\n",
    "\n",
    "\"\"\"\n",
    "corpus = []\n",
    "text = []\n",
    "text_list = []\n",
    "for filename in text_files:\n",
    "    text_str = ''\n",
    "    with open(file=filename, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for count, line in enumerate(lines):\n",
    "            clean_line = remove_stamps_str(line)\n",
    "            text.append(clean_line)\n",
    "    text_list.append(text)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retire tous les timestamps en début de ligne, présents dans chaque transcript\n",
    "def remove_stamps_str(line)->str:\n",
    "    stamp = re.search('.+___', line).group(0)\n",
    "    new_line = line.strip(stamp)\n",
    "    return new_line\n",
    "\n",
    "#Retire les charactères non-ascii \n",
    "def remove_nonascii(line)->str:\n",
    "    ascii_line = line.encode(encoding = 'ascii', errors = 'ignore').decode()\n",
    "    return ascii_line\n",
    "\n",
    "#met tout en minuscules, retire les nombres et stopwords\n",
    "def clean_stopwords_digits(line)->str:\n",
    "    new_line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    new_line = ' '.join([word.lower() for word in new_line.split() if (len(word) >=2 and word.isalpha())])\n",
    "    return new_line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3g5yACwYnA_10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3g5yACwYnA_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3g5yACwYnA_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3g5yACwYnA_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21860</th>\n",
       "      <td>zwTrXwi54us_6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861</th>\n",
       "      <td>zwTrXwi54us_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>zwTrXwi54us_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21863</th>\n",
       "      <td>zwTrXwi54us_9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21864</th>\n",
       "      <td>zx4W0Vuus-I_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21865 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  anger  disgust  fear  happiness  sadness  surprise  \\\n",
       "0       --qXJuDtHPw_5      0        0     0          1        0         0   \n",
       "1      -3g5yACwYnA_10      0        0     0          0        0         0   \n",
       "2      -3g5yACwYnA_13      0        0     0          0        0         0   \n",
       "3       -3g5yACwYnA_2      0        0     0          1        0         0   \n",
       "4       -3g5yACwYnA_3      0        0     0          0        0         0   \n",
       "...               ...    ...      ...   ...        ...      ...       ...   \n",
       "21860   zwTrXwi54us_6      0        0     0          0        0         0   \n",
       "21861   zwTrXwi54us_7      0        0     0          0        0         0   \n",
       "21862   zwTrXwi54us_8      0        0     0          0        0         0   \n",
       "21863   zwTrXwi54us_9      0        0     0          0        0         0   \n",
       "21864   zx4W0Vuus-I_1      0        0     0          1        0         0   \n",
       "\n",
       "       sentiment  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "21860          0  \n",
       "21861          0  \n",
       "21862          0  \n",
       "21863          1  \n",
       "21864          1  \n",
       "\n",
       "[21865 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_df = pd.read_csv(\"../data/interim/labels/interim.csv\")\n",
    "display(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = (text for text in text_list_generator(text_files))\n",
    "df_text = pd.DataFrame(corpus)\n",
    "df_text.columns = ['id', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in this image the two circles are your two and the writers labels point'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = 'In this image, the two circles are your two datase1230912ts, and the writers labels point.'\n",
    "\n",
    "clean_stopwords_digits(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_0</td>\n",
       "      <td>I see that there are three category of writers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--qXJuDtHPw_1</td>\n",
       "      <td>I define them as being an author, a writer, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--qXJuDtHPw_2</td>\n",
       "      <td>An author, I like to classify as somebody who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--qXJuDtHPw_3</td>\n",
       "      <td>These are the well-known authors of our time a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--qXJuDtHPw_4</td>\n",
       "      <td>Then, there is the writer.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text\n",
       "0  --qXJuDtHPw_0    I see that there are three category of writers.\n",
       "1  --qXJuDtHPw_1  I define them as being an author, a writer, an...\n",
       "2  --qXJuDtHPw_2  An author, I like to classify as somebody who ...\n",
       "3  --qXJuDtHPw_3  These are the well-known authors of our time a...\n",
       "4  --qXJuDtHPw_4                         Then, there is the writer."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_text.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'see that there are three category of writers'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_stopwords_digits('I see that there are three category of writers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_0</td>\n",
       "      <td>I see that there are three category of writers.</td>\n",
       "      <td>see that there are three category of writers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--qXJuDtHPw_1</td>\n",
       "      <td>I define them as being an author, a writer, an...</td>\n",
       "      <td>define them as being an author writer and stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--qXJuDtHPw_2</td>\n",
       "      <td>An author, I like to classify as somebody who ...</td>\n",
       "      <td>an author like to classify as somebody who wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--qXJuDtHPw_3</td>\n",
       "      <td>These are the well-known authors of our time a...</td>\n",
       "      <td>these are the wellknown authors of our time an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--qXJuDtHPw_4</td>\n",
       "      <td>Then, there is the writer.</td>\n",
       "      <td>then there is the writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>_ZlF5Q9W1DM_1</td>\n",
       "      <td>Clearly because everything is data driven toda...</td>\n",
       "      <td>clearly because everything is data driven toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>_ZlF5Q9W1DM_2</td>\n",
       "      <td>But the conceptual drivers, what sort of drive...</td>\n",
       "      <td>but the conceptual drivers what sort of drives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44974</th>\n",
       "      <td>_ZlF5Q9W1DM_3</td>\n",
       "      <td>So those two things actually I think rub up ag...</td>\n",
       "      <td>so those two things actually think rub up agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>_ZlF5Q9W1DM_4</td>\n",
       "      <td>So the idea of numbers telling the story up ag...</td>\n",
       "      <td>so the idea of numbers telling the story up ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>_ZlF5Q9W1DM_5</td>\n",
       "      <td>So I think those two things together are incre...</td>\n",
       "      <td>so think those two things together are incredi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0      --qXJuDtHPw_0    I see that there are three category of writers.   \n",
       "1      --qXJuDtHPw_1  I define them as being an author, a writer, an...   \n",
       "2      --qXJuDtHPw_2  An author, I like to classify as somebody who ...   \n",
       "3      --qXJuDtHPw_3  These are the well-known authors of our time a...   \n",
       "4      --qXJuDtHPw_4                         Then, there is the writer.   \n",
       "...              ...                                                ...   \n",
       "44972  _ZlF5Q9W1DM_1  Clearly because everything is data driven toda...   \n",
       "44973  _ZlF5Q9W1DM_2  But the conceptual drivers, what sort of drive...   \n",
       "44974  _ZlF5Q9W1DM_3  So those two things actually I think rub up ag...   \n",
       "44975  _ZlF5Q9W1DM_4  So the idea of numbers telling the story up ag...   \n",
       "44976  _ZlF5Q9W1DM_5  So I think those two things together are incre...   \n",
       "\n",
       "                                              clean_text  \n",
       "0           see that there are three category of writers  \n",
       "1      define them as being an author writer and stor...  \n",
       "2      an author like to classify as somebody who wri...  \n",
       "3      these are the wellknown authors of our time an...  \n",
       "4                               then there is the writer  \n",
       "...                                                  ...  \n",
       "44972  clearly because everything is data driven toda...  \n",
       "44973  but the conceptual drivers what sort of drives...  \n",
       "44974  so those two things actually think rub up agai...  \n",
       "44975  so the idea of numbers telling the story up ag...  \n",
       "44976  so think those two things together are incredi...  \n",
       "\n",
       "[44977 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_text['text'] =  df_text.text.apply(remove_nonascii)\n",
    "\n",
    "\n",
    "df_text['clean_text'] = df_text.text.apply(lambda s : clean_stopwords_digits(s))\n",
    "#df_text['tokens'] = df_text.clean_text.apply(lambda x : x.split(' '))\n",
    "\n",
    "#df_text['lines'] = df_text.groupby('unique_id')\n",
    "#df_text['count'] = df_text['text'].apply(lambda x : len(x.split(' ')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_5</td>\n",
       "      <td>I see that a writer is somebody who has an inc...</td>\n",
       "      <td>see that writer is somebody who has an incredi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3g5yACwYnA_2</td>\n",
       "      <td>Key Polymer brings a technical aspect to our o...</td>\n",
       "      <td>key polymer brings technical aspect to our ope...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3g5yACwYnA_3</td>\n",
       "      <td>We're a huge user of adhesives for our operati...</td>\n",
       "      <td>were huge user of adhesives for our operation ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3g5yACwYnA_4</td>\n",
       "      <td>Key brings those types of aspects to a busines...</td>\n",
       "      <td>key brings those types of aspects to business ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3g5yACwYnA_9</td>\n",
       "      <td>We have many new opportunities through the way...</td>\n",
       "      <td>we have many new opportunities through the way...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15384</th>\n",
       "      <td>_xjBqNfiEY4_6</td>\n",
       "      <td>And once again, U of I students are so well pr...</td>\n",
       "      <td>and once again of students are so well prepare...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15385</th>\n",
       "      <td>_XWUKMkxa-Q_4</td>\n",
       "      <td>So its become more of an iterative process wit...</td>\n",
       "      <td>so its become more of an iterative process wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15386</th>\n",
       "      <td>_YzIvwvyIq4_5</td>\n",
       "      <td>Secondly, using social, you know, things like ...</td>\n",
       "      <td>secondly using social you know things like twi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15387</th>\n",
       "      <td>_ZlF5Q9W1DM_0</td>\n",
       "      <td>JOHN GERZEMA: When I think about finding insig...</td>\n",
       "      <td>john gerzema when think about finding insights...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15388</th>\n",
       "      <td>_ZlF5Q9W1DM_5</td>\n",
       "      <td>So I think those two things together are incre...</td>\n",
       "      <td>so think those two things together are incredi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15389 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0      --qXJuDtHPw_5  I see that a writer is somebody who has an inc...   \n",
       "1      -3g5yACwYnA_2  Key Polymer brings a technical aspect to our o...   \n",
       "2      -3g5yACwYnA_3  We're a huge user of adhesives for our operati...   \n",
       "3      -3g5yACwYnA_4  Key brings those types of aspects to a busines...   \n",
       "4      -3g5yACwYnA_9  We have many new opportunities through the way...   \n",
       "...              ...                                                ...   \n",
       "15384  _xjBqNfiEY4_6  And once again, U of I students are so well pr...   \n",
       "15385  _XWUKMkxa-Q_4  So its become more of an iterative process wit...   \n",
       "15386  _YzIvwvyIq4_5  Secondly, using social, you know, things like ...   \n",
       "15387  _ZlF5Q9W1DM_0  JOHN GERZEMA: When I think about finding insig...   \n",
       "15388  _ZlF5Q9W1DM_5  So I think those two things together are incre...   \n",
       "\n",
       "                                              clean_text  anger  disgust  \\\n",
       "0      see that writer is somebody who has an incredi...      0        0   \n",
       "1      key polymer brings technical aspect to our ope...      0        0   \n",
       "2      were huge user of adhesives for our operation ...      0        0   \n",
       "3      key brings those types of aspects to business ...      0        0   \n",
       "4      we have many new opportunities through the way...      0        0   \n",
       "...                                                  ...    ...      ...   \n",
       "15384  and once again of students are so well prepare...      0        0   \n",
       "15385  so its become more of an iterative process wit...      0        0   \n",
       "15386  secondly using social you know things like twi...      0        0   \n",
       "15387  john gerzema when think about finding insights...      0        0   \n",
       "15388  so think those two things together are incredi...      0        0   \n",
       "\n",
       "       fear  happiness  sadness  surprise  sentiment  \n",
       "0         0          1        0         0          1  \n",
       "1         0          1        0         0          0  \n",
       "2         0          0        0         0          0  \n",
       "3         0          0        0         0          0  \n",
       "4         0          0        0         0          1  \n",
       "...     ...        ...      ...       ...        ...  \n",
       "15384     0          0        0         0          0  \n",
       "15385     0          1        0         0          1  \n",
       "15386     0          1        0         0          1  \n",
       "15387     0          0        0         0          0  \n",
       "15388     0          0        0         0          0  \n",
       "\n",
       "[15389 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.merge(df_text, label_df, on = 'id', how = 'inner')\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7487\n",
       "2    4996\n",
       "0    2906\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_polarity_df = frame.copy()\n",
    "emotions = ['anger', 'disgust','fear','happiness','sadness', 'surprise']\n",
    "new_polarity_df.drop(columns=['id', 'text','anger', 'disgust','fear','happiness','sadness', 'surprise'], inplace= True)\n",
    "new_polarity_df.sentiment = new_polarity_df.sentiment.apply(lambda x : x+1)\n",
    "display(new_polarity_df.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    7487\n",
       " 1    4996\n",
       "-1    2906\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_polarity_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "347/347 [==============================] - ETA: 0s - loss: 0.8096 - accuracy: 0.6181 - precision: 0.6586 - recall: 0.5178 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.69422, saving model to checkpoint_model2.h5\n",
      "347/347 [==============================] - 3787s 11s/step - loss: 0.8096 - accuracy: 0.6181 - precision: 0.6586 - recall: 0.5178 - val_loss: 0.6777 - val_accuracy: 0.6942 - val_precision: 0.7195 - val_recall: 0.6325\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - ETA: 0s - loss: 0.6407 - accuracy: 0.7248 - precision: 0.7423 - recall: 0.6806\n",
      "Epoch 2: val_accuracy did not improve from 0.69422\n",
      "347/347 [==============================] - 3691s 11s/step - loss: 0.6407 - accuracy: 0.7248 - precision: 0.7423 - recall: 0.6806 - val_loss: 0.6733 - val_accuracy: 0.6910 - val_precision: 0.7025 - val_recall: 0.6682\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.7994 - precision: 0.8132 - recall: 0.7782\n",
      "Epoch 3: val_accuracy did not improve from 0.69422\n",
      "347/347 [==============================] - 3643s 11s/step - loss: 0.5006 - accuracy: 0.7994 - precision: 0.8132 - recall: 0.7782 - val_loss: 0.7432 - val_accuracy: 0.6708 - val_precision: 0.6823 - val_recall: 0.6458\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#from emotion import module_dir, root_dir\n",
    "root_dir = '../../../'\n",
    "module_dir = '../../'\n",
    "\"\"\"\n",
    "MAX_LEN = 128\n",
    "\n",
    "#SENTS_DIR = PATH(root_dir / \"data/process/polarity_balanced.csv\")\n",
    "module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "BERT_LAYER = hub.KerasLayer(module_url, trainable=True)\n",
    "TOKENIZER = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "#DATA_DIR = (root_dir + 'data/processed/text/')\n",
    "\n",
    "\n",
    "\n",
    "#Interesting/meaningful metrics\n",
    "METRICS = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(name = 'accuracy'),\n",
    "    tf.keras.metrics.Precision(name = 'precision'),\n",
    "    tf.keras.metrics.Recall(name = 'recall')\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#Encodes lists of texts into BERT-useable tensors\n",
    "def bert_encode(texts, tokenizer=TOKENIZER, max_len=MAX_LEN):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "\n",
    "#Building a neural-net that uses BERT embeddings\n",
    "def build_model(bert_layer=BERT_LAYER, max_len=MAX_LEN):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    #net = tf.keras.layers.Dense(128, activation= 'relu')(clf_output)\n",
    "    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    out = tf.keras.layers.Dense(3, activation='softmax')(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08), loss='categorical_crossentropy', metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_dnn(model, X_train, y_train, e=3):\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('checkpoint_model2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
    "\n",
    "    train_input = bert_encode(X_train)\n",
    "    train_labels = y_train\n",
    "\n",
    "    train_history = model.fit(\n",
    "            train_input, train_labels, \n",
    "            validation_split=0.2,\n",
    "            epochs=e,\n",
    "            callbacks=[checkpoint, earlystopping],\n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "            )\n",
    "    return train_history\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#data = pd.read_csv('polarity_balanced.csv')\n",
    "data = new_polarity_df\n",
    "x = data.clean_text.values\n",
    "dummy_sents = pd.get_dummies(data.sentiment)\n",
    "y = dummy_sents.values\n",
    "X_train, X_test, y_train, y_test = tts(x, y, test_size = 0.1)\n",
    "model2 = build_model()\n",
    "\n",
    "histo = train_dnn(model2, X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_json2 = model2.to_json()\n",
    "with open(f\"text_model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json2)\n",
    "model2.save_weights(\"weights2.h5\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18fb571ca60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('checkpoint_model2.h5', custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
      "                                 (None, 128, 768)]                'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['keras_layer[0][1]']            \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           2080        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            99          ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,533,636\n",
      "Trainable params: 109,533,635\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['I really really love this!', 'This is awful']\n",
    "enc_texts = bert_encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 265ms/step\n",
      "2 0.9580000042915344 %\n",
      "0 0.9710000157356262 %\n"
     ]
    }
   ],
   "source": [
    "for pred in loaded_model.predict(enc_texts):\n",
    "    prob = max(pred)\n",
    "    print(np.argmax(pred), f\"{np.round(prob, 3)} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_polarity_df.to_csv('polarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e016b4092f2f33b22d7afb9b895ac58d1e1c55d21f6dd8227b43a776f59f225e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"../data/raw/text\"\n",
    "labels_dir =  \"../data/raw/labels\"\n",
    "audio_dir = \"../data/raw/audio\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'_7HVhnSYX1Y___21___125.556___127.594___Nothing dangerous'.split('___')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob(f\"{text_dir}/*.txt\")\n",
    "\n",
    "\n",
    "def remove_stamps_str(line)->str:\n",
    "    #clip_num = re.search('.+___\\d\\d?\\d?___.+', line).group(0)\n",
    "    stamp = re.search('.+___', line).group(0)\n",
    "    new_line = line.strip(stamp)\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncorpus = []\\ntext = []\\ntext_list = []\\nfor filename in text_files:\\n    text_str = ''\\n    with open(file=filename, encoding='utf-8') as f:\\n        lines = f.readlines()\\n        for count, line in enumerate(lines):\\n            clean_line = remove_stamps_str(line)\\n            text.append(clean_line)\\n    text_list.append(text)\\n    \""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Pour python < 3.9, sinon str.removeprefix() de base\n",
    "def removeprefix(self: str, prefix: str, /) -> str:\n",
    "    if self.startswith(prefix):\n",
    "        return self[len(prefix):]\n",
    "    else:\n",
    "        return self[:]\n",
    "\n",
    "\n",
    "\n",
    "#Retire chaque stamps, chaque texte devien 1 seul str\n",
    "\n",
    "def text_list_generator(files_list):\n",
    "    text_list = []\n",
    "    for filename in files_list:\n",
    "        with open(file = filename, encoding = 'utf-8') as f:\n",
    "\n",
    "            ##WINDOWS SPECIFIC\n",
    "           # videoid = filename.removeprefix(text_dir + '\\\\').rstrip('.txt')\n",
    "            videoid = removeprefix(filename, text_dir + '\\\\').rstrip('.txt')\n",
    "            lines = f.readlines()\n",
    "            for line_number, text_line in enumerate(lines):\n",
    "                clean_line = remove_stamps_str(text_line)\n",
    "                clip_id = videoid +'_'+ text_line.split('___')[1]\n",
    "                #clip_id = videoid +'_' +str(line_number)\n",
    "                yield (clip_id, clean_line.rstrip())\n",
    "\n",
    "\"\"\"\n",
    "corpus = []\n",
    "text = []\n",
    "text_list = []\n",
    "for filename in text_files:\n",
    "    text_str = ''\n",
    "    with open(file=filename, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for count, line in enumerate(lines):\n",
    "            clean_line = remove_stamps_str(line)\n",
    "            text.append(clean_line)\n",
    "    text_list.append(text)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('English')\n",
    "\n",
    "#création d'un dict pour lookup en O(1)\n",
    "stopwords_dict = Counter(stop_words)\n",
    "\n",
    "\n",
    "#Retire tous les timestamps en début de ligne, présents dans chaque transcript\n",
    "def remove_stamps_str(line)->str:\n",
    "    stamp = re.search('.+___', line).group(0)\n",
    "    new_line = line.strip(stamp)\n",
    "    return new_line\n",
    "\n",
    "#Retire les charactères non-ascii \n",
    "def remove_nonascii(line)->str:\n",
    "    ascii_line = line.encode(encoding = 'ascii', errors = 'ignore').decode()\n",
    "    return ascii_line\n",
    "\n",
    "#met tout en minuscules, retire les nombres et stopwords\n",
    "def clean_stopwords_digits(line)->str:\n",
    "    new_line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    new_line = ' '.join([word.lower() for word in new_line.split() if (len(word) >=2 and word.isalpha() and word not in stopwords_dict)])\n",
    "    return new_line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3g5yACwYnA_10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3g5yACwYnA_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3g5yACwYnA_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3g5yACwYnA_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21813</th>\n",
       "      <td>zwTrXwi54us_6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21814</th>\n",
       "      <td>zwTrXwi54us_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21815</th>\n",
       "      <td>zwTrXwi54us_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <td>zwTrXwi54us_9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21817</th>\n",
       "      <td>zx4W0Vuus-I_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21818 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  anger  disgust  fear  happiness  sadness  surprise  \\\n",
       "0       --qXJuDtHPw_5      0        0     0          1        0         0   \n",
       "1      -3g5yACwYnA_10      0        0     0          0        0         0   \n",
       "2      -3g5yACwYnA_13      0        0     0          0        0         0   \n",
       "3       -3g5yACwYnA_2      0        0     0          1        0         0   \n",
       "4       -3g5yACwYnA_3      0        0     0          0        0         0   \n",
       "...               ...    ...      ...   ...        ...      ...       ...   \n",
       "21813   zwTrXwi54us_6      0        0     0          0        0         0   \n",
       "21814   zwTrXwi54us_7      0        0     0          0        0         0   \n",
       "21815   zwTrXwi54us_8      0        0     0          0        0         0   \n",
       "21816   zwTrXwi54us_9      0        0     0          0        0         0   \n",
       "21817   zx4W0Vuus-I_1      0        0     0          1        0         0   \n",
       "\n",
       "       sentiment  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "21813          0  \n",
       "21814          0  \n",
       "21815          0  \n",
       "21816          1  \n",
       "21817          1  \n",
       "\n",
       "[21818 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_df = pd.read_csv(\"../data/interim/labels/labels.csv\")\n",
    "display(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = (text for text in text_list_generator(text_files))\n",
    "df_text = pd.DataFrame(corpus)\n",
    "df_text.columns = ['id', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_0</td>\n",
       "      <td>I see that there are three category of writers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--qXJuDtHPw_1</td>\n",
       "      <td>I define them as being an author, a writer, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--qXJuDtHPw_2</td>\n",
       "      <td>An author, I like to classify as somebody who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--qXJuDtHPw_3</td>\n",
       "      <td>These are the well-known authors of our time a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--qXJuDtHPw_4</td>\n",
       "      <td>Then, there is the writer.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text\n",
       "0  --qXJuDtHPw_0    I see that there are three category of writers.\n",
       "1  --qXJuDtHPw_1  I define them as being an author, a writer, an...\n",
       "2  --qXJuDtHPw_2  An author, I like to classify as somebody who ...\n",
       "3  --qXJuDtHPw_3  These are the well-known authors of our time a...\n",
       "4  --qXJuDtHPw_4                         Then, there is the writer."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_text.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_0</td>\n",
       "      <td>I see that there are three category of writers.</td>\n",
       "      <td>see three category writers</td>\n",
       "      <td>[see, three, category, writers]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--qXJuDtHPw_1</td>\n",
       "      <td>I define them as being an author, a writer, an...</td>\n",
       "      <td>define author writer story teller</td>\n",
       "      <td>[define, author, writer, story, teller]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--qXJuDtHPw_2</td>\n",
       "      <td>An author, I like to classify as somebody who ...</td>\n",
       "      <td>an author like classify somebody writes great ...</td>\n",
       "      <td>[an, author, like, classify, somebody, writes,...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--qXJuDtHPw_3</td>\n",
       "      <td>These are the well-known authors of our time a...</td>\n",
       "      <td>these wellknown authors time past</td>\n",
       "      <td>[these, wellknown, authors, time, past]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--qXJuDtHPw_4</td>\n",
       "      <td>Then, there is the writer.</td>\n",
       "      <td>then writer</td>\n",
       "      <td>[then, writer]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>_ZlF5Q9W1DM_1</td>\n",
       "      <td>Clearly because everything is data driven toda...</td>\n",
       "      <td>clearly everything data driven today measurabl...</td>\n",
       "      <td>[clearly, everything, data, driven, today, mea...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>_ZlF5Q9W1DM_2</td>\n",
       "      <td>But the conceptual drivers, what sort of drive...</td>\n",
       "      <td>but conceptual drivers sort drives passions th...</td>\n",
       "      <td>[but, conceptual, drivers, sort, drives, passi...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44974</th>\n",
       "      <td>_ZlF5Q9W1DM_3</td>\n",
       "      <td>So those two things actually I think rub up ag...</td>\n",
       "      <td>so two things actually think rub collide reall...</td>\n",
       "      <td>[so, two, things, actually, think, rub, collid...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>_ZlF5Q9W1DM_4</td>\n",
       "      <td>So the idea of numbers telling the story up ag...</td>\n",
       "      <td>so idea numbers telling story idea explaining ...</td>\n",
       "      <td>[so, idea, numbers, telling, story, idea, expl...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>_ZlF5Q9W1DM_5</td>\n",
       "      <td>So I think those two things together are incre...</td>\n",
       "      <td>so think two things together incredibly import...</td>\n",
       "      <td>[so, think, two, things, together, incredibly,...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44977 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0      --qXJuDtHPw_0    I see that there are three category of writers.   \n",
       "1      --qXJuDtHPw_1  I define them as being an author, a writer, an...   \n",
       "2      --qXJuDtHPw_2  An author, I like to classify as somebody who ...   \n",
       "3      --qXJuDtHPw_3  These are the well-known authors of our time a...   \n",
       "4      --qXJuDtHPw_4                         Then, there is the writer.   \n",
       "...              ...                                                ...   \n",
       "44972  _ZlF5Q9W1DM_1  Clearly because everything is data driven toda...   \n",
       "44973  _ZlF5Q9W1DM_2  But the conceptual drivers, what sort of drive...   \n",
       "44974  _ZlF5Q9W1DM_3  So those two things actually I think rub up ag...   \n",
       "44975  _ZlF5Q9W1DM_4  So the idea of numbers telling the story up ag...   \n",
       "44976  _ZlF5Q9W1DM_5  So I think those two things together are incre...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0                             see three category writers   \n",
       "1                      define author writer story teller   \n",
       "2      an author like classify somebody writes great ...   \n",
       "3                      these wellknown authors time past   \n",
       "4                                            then writer   \n",
       "...                                                  ...   \n",
       "44972  clearly everything data driven today measurabl...   \n",
       "44973  but conceptual drivers sort drives passions th...   \n",
       "44974  so two things actually think rub collide reall...   \n",
       "44975  so idea numbers telling story idea explaining ...   \n",
       "44976  so think two things together incredibly import...   \n",
       "\n",
       "                                                  tokens  count  \n",
       "0                        [see, three, category, writers]      9  \n",
       "1                [define, author, writer, story, teller]     13  \n",
       "2      [an, author, like, classify, somebody, writes,...     14  \n",
       "3                [these, wellknown, authors, time, past]     11  \n",
       "4                                         [then, writer]      5  \n",
       "...                                                  ...    ...  \n",
       "44972  [clearly, everything, data, driven, today, mea...     17  \n",
       "44973  [but, conceptual, drivers, sort, drives, passi...     28  \n",
       "44974  [so, two, things, actually, think, rub, collid...     21  \n",
       "44975  [so, idea, numbers, telling, story, idea, expl...     40  \n",
       "44976  [so, think, two, things, together, incredibly,...     23  \n",
       "\n",
       "[44977 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_text['text'] =  df_text.text.apply(remove_nonascii)\n",
    "\n",
    "\n",
    "df_text['clean_text'] = df_text.text.apply(lambda s : clean_stopwords_digits(s))\n",
    "df_text['tokens'] = df_text.clean_text.apply(lambda x : x.split(' '))\n",
    "\n",
    "#df_text['lines'] = df_text.groupby('unique_id')\n",
    "df_text['count'] = df_text['text'].apply(lambda x : len(x.split(' ')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame = frame[~frame[target_features].sum(axis = 1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>count</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_5</td>\n",
       "      <td>I see that a writer is somebody who has an inc...</td>\n",
       "      <td>see writer somebody incredible command mechani...</td>\n",
       "      <td>[see, writer, somebody, incredible, command, m...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3g5yACwYnA_2</td>\n",
       "      <td>Key Polymer brings a technical aspect to our o...</td>\n",
       "      <td>key polymer brings technical aspect operation ...</td>\n",
       "      <td>[key, polymer, brings, technical, aspect, oper...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3g5yACwYnA_3</td>\n",
       "      <td>We're a huge user of adhesives for our operati...</td>\n",
       "      <td>were huge user adhesives operation called floc...</td>\n",
       "      <td>[were, huge, user, adhesives, operation, calle...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3g5yACwYnA_4</td>\n",
       "      <td>Key brings those types of aspects to a busines...</td>\n",
       "      <td>key brings types aspects business new markets ...</td>\n",
       "      <td>[key, brings, types, aspects, business, new, m...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3g5yACwYnA_9</td>\n",
       "      <td>We have many new opportunities through the way...</td>\n",
       "      <td>we many new opportunities way things changed y...</td>\n",
       "      <td>[we, many, new, opportunities, way, things, ch...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>_xjBqNfiEY4_6</td>\n",
       "      <td>And once again, U of I students are so well pr...</td>\n",
       "      <td>and students well prepared asset student</td>\n",
       "      <td>[and, students, well, prepared, asset, student]</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>_XWUKMkxa-Q_4</td>\n",
       "      <td>So its become more of an iterative process wit...</td>\n",
       "      <td>so become iterative process fast results fast ...</td>\n",
       "      <td>[so, become, iterative, process, fast, results...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>_YzIvwvyIq4_5</td>\n",
       "      <td>Secondly, using social, you know, things like ...</td>\n",
       "      <td>secondly using social know things like twitter...</td>\n",
       "      <td>[secondly, using, social, know, things, like, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>_ZlF5Q9W1DM_0</td>\n",
       "      <td>JOHN GERZEMA: When I think about finding insig...</td>\n",
       "      <td>john gerzema when think finding insights consu...</td>\n",
       "      <td>[john, gerzema, when, think, finding, insights...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>_ZlF5Q9W1DM_5</td>\n",
       "      <td>So I think those two things together are incre...</td>\n",
       "      <td>so think two things together incredibly import...</td>\n",
       "      <td>[so, think, two, things, together, incredibly,...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21598 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0      --qXJuDtHPw_5  I see that a writer is somebody who has an inc...   \n",
       "1      -3g5yACwYnA_2  Key Polymer brings a technical aspect to our o...   \n",
       "2      -3g5yACwYnA_3  We're a huge user of adhesives for our operati...   \n",
       "3      -3g5yACwYnA_4  Key brings those types of aspects to a busines...   \n",
       "4      -3g5yACwYnA_9  We have many new opportunities through the way...   \n",
       "...              ...                                                ...   \n",
       "21593  _xjBqNfiEY4_6  And once again, U of I students are so well pr...   \n",
       "21594  _XWUKMkxa-Q_4  So its become more of an iterative process wit...   \n",
       "21595  _YzIvwvyIq4_5  Secondly, using social, you know, things like ...   \n",
       "21596  _ZlF5Q9W1DM_0  JOHN GERZEMA: When I think about finding insig...   \n",
       "21597  _ZlF5Q9W1DM_5  So I think those two things together are incre...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0      see writer somebody incredible command mechani...   \n",
       "1      key polymer brings technical aspect operation ...   \n",
       "2      were huge user adhesives operation called floc...   \n",
       "3      key brings types aspects business new markets ...   \n",
       "4      we many new opportunities way things changed y...   \n",
       "...                                                  ...   \n",
       "21593           and students well prepared asset student   \n",
       "21594  so become iterative process fast results fast ...   \n",
       "21595  secondly using social know things like twitter...   \n",
       "21596  john gerzema when think finding insights consu...   \n",
       "21597  so think two things together incredibly import...   \n",
       "\n",
       "                                                  tokens  count  anger  \\\n",
       "0      [see, writer, somebody, incredible, command, m...     18      0   \n",
       "1      [key, polymer, brings, technical, aspect, oper...     14      0   \n",
       "2      [were, huge, user, adhesives, operation, calle...     29      0   \n",
       "3      [key, brings, types, aspects, business, new, m...     34      0   \n",
       "4      [we, many, new, opportunities, way, things, ch...     21      0   \n",
       "...                                                  ...    ...    ...   \n",
       "21593    [and, students, well, prepared, asset, student]     24      0   \n",
       "21594  [so, become, iterative, process, fast, results...     13      0   \n",
       "21595  [secondly, using, social, know, things, like, ...     30      0   \n",
       "21596  [john, gerzema, when, think, finding, insights...     24      0   \n",
       "21597  [so, think, two, things, together, incredibly,...     23      0   \n",
       "\n",
       "       disgust  fear  happiness  sadness  surprise  sentiment  \n",
       "0            0     0          1        0         0          1  \n",
       "1            0     0          1        0         0          0  \n",
       "2            0     0          0        0         0          0  \n",
       "3            0     0          0        0         0          0  \n",
       "4            0     0          0        0         0          1  \n",
       "...        ...   ...        ...      ...       ...        ...  \n",
       "21593        0     0          0        0         0          0  \n",
       "21594        0     0          1        0         0          1  \n",
       "21595        0     0          1        0         0          1  \n",
       "21596        0     0          0        0         0          0  \n",
       "21597        0     0          0        0         0          0  \n",
       "\n",
       "[21598 rows x 12 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.merge(df_text, label_df, on = 'id', how = 'inner')\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['anger', 'disgust', 'fear','happiness', 'sadness','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame[frame[emotions].sum(axis=1) >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=28'>29</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=29'>30</a>\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=30'>31</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:\\\\Users\\\\trott/nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Projet_emotion\\emotion\\notebooks\\text-model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projet_emotion/emotion/notebooks/text-model.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39m#nltk.download('averaged_perceptron_tagger')\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Projet_emotion/emotion/notebooks/text-model.ipynb#ch0000011?line=1'>2</a>\u001b[0m df_text[\u001b[39m'\u001b[39m\u001b[39mtagged\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_text[\u001b[39m'\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(nltk\u001b[39m.\u001b[39;49mtag\u001b[39m.\u001b[39;49mpos_tag )\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\pandas\\core\\series.py:4430\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4319'>4320</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4320'>4321</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4321'>4322</a>\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4324'>4325</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4325'>4326</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4326'>4327</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4327'>4328</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4328'>4329</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4427'>4428</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4428'>4429</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/series.py?line=4429'>4430</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1077'>1078</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1078'>1079</a>\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1079'>1080</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1081'>1082</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1130'>1131</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1131'>1132</a>\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1132'>1133</a>\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1133'>1134</a>\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1134'>1135</a>\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1135'>1136</a>\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1136'>1137</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1137'>1138</a>\u001b[0m             values,\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1138'>1139</a>\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1139'>1140</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1140'>1141</a>\u001b[0m         )\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1142'>1143</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1143'>1144</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1144'>1145</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/pandas/core/apply.py?line=1145'>1146</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\nltk\\tag\\__init__.py:165\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=139'>140</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpos_tag\u001b[39m(tokens, tagset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, lang\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=140'>141</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=141'>142</a>\u001b[0m \u001b[39m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=142'>143</a>\u001b[0m \u001b[39m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=162'>163</a>\u001b[0m \u001b[39m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=163'>164</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=164'>165</a>\u001b[0m     tagger \u001b[39m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=165'>166</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\nltk\\tag\\__init__.py:107\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=104'>105</a>\u001b[0m     tagger\u001b[39m.\u001b[39mload(ap_russian_model_loc)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=105'>106</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=106'>107</a>\u001b[0m     tagger \u001b[39m=\u001b[39m PerceptronTagger()\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/__init__.py?line=107'>108</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\nltk\\tag\\perceptron.py:167\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/perceptron.py?line=163'>164</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/perceptron.py?line=164'>165</a>\u001b[0m \u001b[39mif\u001b[39;00m load:\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/perceptron.py?line=165'>166</a>\u001b[0m     AP_MODEL_LOC \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/perceptron.py?line=166'>167</a>\u001b[0m         find(\u001b[39m\"\u001b[39;49m\u001b[39mtaggers/averaged_perceptron_tagger/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m PICKLE)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/perceptron.py?line=167'>168</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/tag/perceptron.py?line=168'>169</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload(AP_MODEL_LOC)\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\nltk\\data.py:522\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/data.py?line=518'>519</a>\u001b[0m \u001b[39m# Check each item in our path\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/data.py?line=519'>520</a>\u001b[0m \u001b[39mfor\u001b[39;00m path_ \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/data.py?line=520'>521</a>\u001b[0m     \u001b[39m# Is the path item a zipfile?\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/data.py?line=521'>522</a>\u001b[0m     \u001b[39mif\u001b[39;00m path_ \u001b[39mand\u001b[39;00m (os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49misfile(path_) \u001b[39mand\u001b[39;00m path_\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/data.py?line=522'>523</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/nltk/data.py?line=523'>524</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m ZipFilePathPointer(path_, resource_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=27'>28</a>\u001b[0m \u001b[39m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=28'>29</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=29'>30</a>\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=30'>31</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     <a href='file:///c%3A/Users/trott/AppData/Local/Programs/Python/Python39/lib/genericpath.py?line=31'>32</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#df_text['tagged'] = df_text['tokens'].apply(nltk.tag.pos_tag )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'sentiment']\n",
    "\n",
    "#frame['target_vector'] = frame[target_features].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer(lowercase=False, ngram_range=(1,3), max_features=250)\n",
    "counts = count_vector.fit_transform(frame.clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(frame.clean_text,frame[target_features], test_size=0.2)\n",
    "\n",
    "bow_data = tts(frame.clean_text, frame[target_features], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "    ('BoW', count_vector),\n",
    "    ('classifier', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior = None)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multioutput target data is not supported with label binarization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Projet_emotion\\emotion\\notebooks\\text-model.ipynb Cell 24'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Projet_emotion/emotion/notebooks/text-model.ipynb#ch0000018?line=0'>1</a>\u001b[0m nb_pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projet_emotion/emotion/notebooks/text-model.ipynb#ch0000018?line=1'>2</a>\u001b[0m preds \u001b[39m=\u001b[39m nb_pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projet_emotion/emotion/notebooks/text-model.ipynb#ch0000018?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest accuracy : \u001b[39m\u001b[39m{\u001b[39;00maccuracy_score(y_test, preds)\u001b[39m.\u001b[39mround(\u001b[39m3\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/pipeline.py?line=391'>392</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/pipeline.py?line=392'>393</a>\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/pipeline.py?line=393'>394</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/pipeline.py?line=395'>396</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\sklearn\\multiclass.py:330\u001b[0m, in \u001b[0;36mOneVsRestClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=324'>325</a>\u001b[0m \u001b[39m# A sparse LabelBinarizer, with sparse_output=True, has been shown to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=325'>326</a>\u001b[0m \u001b[39m# outperform or match a dense label binarizer in all cases and has also\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=326'>327</a>\u001b[0m \u001b[39m# resulted in less or equal memory consumption in the fit_ovr function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=327'>328</a>\u001b[0m \u001b[39m# overall.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=328'>329</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_binarizer_ \u001b[39m=\u001b[39m LabelBinarizer(sparse_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=329'>330</a>\u001b[0m Y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_binarizer_\u001b[39m.\u001b[39;49mfit_transform(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=330'>331</a>\u001b[0m Y \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mtocsc()\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/multiclass.py?line=331'>332</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_binarizer_\u001b[39m.\u001b[39mclasses_\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:324\u001b[0m, in \u001b[0;36mLabelBinarizer.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=303'>304</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=304'>305</a>\u001b[0m     \u001b[39m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=305'>306</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=306'>307</a>\u001b[0m \u001b[39m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=321'>322</a>\u001b[0m \u001b[39m        will be of CSR format.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=322'>323</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=323'>324</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(y)\u001b[39m.\u001b[39mtransform(y)\n",
      "File \u001b[1;32mc:\\Users\\trott\\ml_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:294\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=291'>292</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_type_ \u001b[39m=\u001b[39m type_of_target(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=292'>293</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmultioutput\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_type_:\n\u001b[1;32m--> <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=293'>294</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=294'>295</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMultioutput target data is not supported with label binarization\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=295'>296</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=296'>297</a>\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/trott/ml_env/lib/site-packages/sklearn/preprocessing/_label.py?line=297'>298</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my has 0 samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y)\n",
      "\u001b[1;31mValueError\u001b[0m: Multioutput target data is not supported with label binarization"
     ]
    }
   ],
   "source": [
    "nb_pipeline.fit(X_train, y_train)\n",
    "preds = nb_pipeline.predict(X_test)\n",
    "\n",
    "print(f'Test accuracy : {accuracy_score(y_test, preds).round(3)}')\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting for anger\n",
      "Test accuracy : 0.8743604320636725\n",
      "Fitting for disgust\n",
      "Test accuracy : 0.8567367822626493\n",
      "Fitting for fear\n",
      "Test accuracy : 0.9874928936895964\n",
      "Fitting for happiness\n",
      "Test accuracy : 0.7674815235929505\n",
      "Fitting for sadness\n",
      "Test accuracy : 0.8544627629334849\n",
      "Fitting for surprise\n",
      "Test accuracy : 0.9778283115406481\n",
      "Fitting for sentiment\n",
      "Test accuracy : 0.602615122228539\n"
     ]
    }
   ],
   "source": [
    "for feature in target_features:\n",
    "    print(f'Fitting for {feature}')\n",
    "    nb_pipeline.fit(X_train, y_train[feature])\n",
    "    preds = nb_pipeline.predict(X_test)\n",
    "    print(f'Test accuracy : {accuracy_score(y_test[feature], preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec as w2v\n",
    "\n",
    "#w2v_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "\n",
    "#SEULEMENT PRENDRE MOT DANS MODEL.VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e016b4092f2f33b22d7afb9b895ac58d1e1c55d21f6dd8227b43a776f59f225e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

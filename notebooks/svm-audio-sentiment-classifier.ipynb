{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22319221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318ba5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5710ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emotion import root_dir, module_dir\n",
    "# ffmpeg binary\n",
    "FFMPEG = \"/usr/bin/ffmpeg\"\n",
    "\n",
    "# text directory\n",
    "TEXT_DIR = Path(root_dir / \"data/raw/text\")\n",
    "LABELS_DIR = Path(root_dir / \"data/raw/labels\")\n",
    "\n",
    "# audio directories\n",
    "AUDIO_DIR = Path(root_dir / \"data/raw/audio\")\n",
    "AUDIO_CLIPS_DIR = Path(root_dir / \"data/interim/audio\")\n",
    "AUDIO_FEATURES_DIR = Path(root_dir / \"data/processed/audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6a4bc",
   "metadata": {},
   "source": [
    "# Load ratings, keep sentiment (positive, negative, none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5b514",
   "metadata": {},
   "source": [
    "## Aggregate : 1 if 2+ raters agree, keep labels having audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a394ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_ratings(labels_dir, split_id_clip = False):\n",
    "    \n",
    "    label_files = glob.glob(f\"{labels_dir}/*.csv\")\n",
    "\n",
    "    df_labels = []\n",
    "\n",
    "    for filename in label_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df_labels.append(df)\n",
    "\n",
    "\n",
    "    df_labels = pd.concat(df_labels, axis=0, ignore_index=True)\n",
    "\n",
    "    # keep only relevant columns\n",
    "    label_cols = ['Input.VIDEO_ID', 'Input.CLIP',\n",
    "              'Answer.anger', 'Answer.disgust',\n",
    "              'Answer.fear', 'Answer.happiness',\n",
    "              'Answer.sadness', 'Answer.surprise',\n",
    "              'Answer.sentiment']\n",
    "\n",
    "    # rename columns to shorter names\n",
    "    label_new_cols = ['id', 'clip',\n",
    "                      'anger', 'disgust',\n",
    "                      'fear', 'happiness',\n",
    "                      'sadness', 'surprise',\n",
    "                      'sentiment']\n",
    "    df_labels = df_labels[label_cols]\n",
    "    df_labels.columns = label_new_cols\n",
    "\n",
    "    # drop row all nan\n",
    "    isna_idx = \\\n",
    "        df_labels.index[df_labels[df_labels.columns[2:]].isna().all(axis=1)]\n",
    "    df_labels.drop(index=isna_idx, inplace=True)\n",
    "    # replace remaining nan's with 0\n",
    "    df_labels = df_labels.replace({np.nan : 0})\n",
    "    # convert ratings to int\n",
    "    df_labels[label_new_cols[2:]] = df_labels[label_new_cols[2:]].astype('Int64')\n",
    "    # set emotions to 0 or 1\n",
    "    df_labels[label_new_cols[2:-1]] = \\\n",
    "        df_labels[label_new_cols[2:-1]].applymap(lambda x : 1 if x > 0 else 0)\n",
    "\n",
    "    # if sentiment > 0 convert to positive = 1, elif < 0 convert to negative = 1\n",
    "    #   if none of emotion or sentiment == 1, set none to 1\n",
    "    df_labels['positive'] = \\\n",
    "        df_labels['sentiment'].map(lambda x : 1 if x > 0 else 0)\n",
    "    df_labels['negative'] = \\\n",
    "        df_labels['sentiment'].map(lambda x : 1 if x < 0 else 0)\n",
    "\n",
    "    # drop sentiment column (now in positive/negative)\n",
    "    df_labels.drop(columns='sentiment', inplace=True)\n",
    "    \n",
    "    df_labels['none'] = 0\n",
    "    none_idx = \\\n",
    "        df_labels[df_labels[df_labels.columns[2:]].sum(axis=1) == 0].index\n",
    "\n",
    "    df_labels.loc[none_idx,'none'] = 1\n",
    "\n",
    "    label_new_cols = ['id', 'clip',\n",
    "                      'anger', 'disgust',\n",
    "                      'fear', 'happiness',\n",
    "                      'sadness', 'surprise',\n",
    "                      'sentiment']\n",
    "    \n",
    "    # remove '/' from id's\n",
    "    df_labels['id'] = df_labels['id'].map(lambda x : str(x).split(\"/\")[-1])\n",
    "    if not split_id_clip:\n",
    "        df_labels['id'] = df_labels['id'] + '_' + df_labels['clip'].astype(str)\n",
    "        df_labels.drop(columns = 'clip', inplace = True)\n",
    "        \n",
    "        label_new_cols = ['id',\n",
    "                          'none', 'positive', 'negative',\n",
    "                          'anger', 'disgust',\n",
    "                          'fear', 'happiness',\n",
    "                          'sadness', 'surprise'\n",
    "                         ]\n",
    "    else:\n",
    "        label_new_cols = ['id', 'clip',\n",
    "                          'none', 'positive', 'negative',\n",
    "                          'anger', 'disgust',\n",
    "                          'fear', 'happiness',\n",
    "                          'sadness', 'surprise'\n",
    "                         ]\n",
    "        \n",
    "    df_labels = df_labels[label_new_cols]\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "969bf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_ratings(ratings):\n",
    "    '''\n",
    "        aggregate labels to 1 if 2+ ratings aggree else 0\n",
    "        ratings : pd.DataFrame containing all ratings (3 per example)\n",
    "        returns : pd.DataFrame containing aggregated labels\n",
    "    '''\n",
    "    grp_labels = ratings.groupby('id').sum()\n",
    "    # label to 1 if > 1 else 0\n",
    "    grp_labels = grp_labels.applymap(lambda x : 1 if x > 1 else 0)\n",
    "    # drop rows where all == 0\n",
    "    idx = grp_labels[grp_labels.sum(axis =1) == 0].index\n",
    "    grp_labels.drop(index = idx, inplace=True)\n",
    "    print(f\"{len(idx)} rows dropped\")\n",
    "    print(f\"{grp_labels.shape[0]} grouped labels\")\n",
    "    return grp_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc2ef3",
   "metadata": {},
   "source": [
    "# Load sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0838065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_labels(labels_dir, audio_dir):\n",
    "    '''\n",
    "        get sentiment labels (none, positive, negative) having audio clips\n",
    "        labels_dir : directory containing labels .csv files (ratings)\n",
    "        audio_dir  : directory containing segmented audio clips\n",
    "        returns    : pd.DataFrame containing sentiment labels having audio clips\n",
    "    '''\n",
    "    all_ratings = load_all_ratings(labels_dir)\n",
    "    # keep ratings having positive, negative or none\n",
    "    mask_positive = all_ratings['positive'] == 1\n",
    "    mask_negative = all_ratings['negative'] == 1\n",
    "    mask_none = all_ratings['none'] == 1\n",
    "    sentiment_ratings = \\\n",
    "        all_ratings[(mask_positive) | (mask_negative) | (mask_none)]\\\n",
    "            [['id','none','positive','negative']].copy()\n",
    "    # aggregate ratings\n",
    "    sentiment_labels = aggregate_ratings(sentiment_ratings)\n",
    "    # get audio clip names\n",
    "    audio_clip_names = glob.glob(f\"{audio_dir}/*.wav\")\n",
    "    audio_clip_names = \\\n",
    "        [cn.rsplit('.', maxsplit = 1)[0].rsplit('/', maxsplit = 1)[-1] for \\\n",
    "             cn in audio_clip_names]\n",
    "    clips_no_audio = []\n",
    "    for idx in sentiment_labels.index:\n",
    "        if idx not in audio_clip_names:\n",
    "            clips_no_audio.append(idx)\n",
    "    sentiment_labels.drop(index=clips_no_audio, inplace=True)\n",
    "    print(f\"{sentiment_labels.shape[0]} labels for sentiment with audio\")\n",
    "    return sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_clips(labels_dir):\n",
    "    '''\n",
    "        get id & clip number from labels\n",
    "        labels_dir : directory containing raw labels\n",
    "        returns   : dict of ids with correponding labeled clips\n",
    "                    {'id' : [clip1, clip2, ... clip_n]}\n",
    "    '''\n",
    "    labeled_clips = {}\n",
    "    labels = load_all_ratings(labels_dir, split_id_clip=True)\n",
    "\n",
    "    labels = labels.drop_duplicates(subset=['id','clip'])\n",
    "\n",
    "    uniq_ids = sorted(list(labels['id'].unique()))\n",
    "    for i in uniq_ids:\n",
    "        labeled_clips[i] = \\\n",
    "            sorted(\n",
    "                labels[labels['id'] == i]['clip'].astype(int).to_list()\n",
    "            )\n",
    "    del labels\n",
    "    return labeled_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f03e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clips_info_from_text(text_dir, get_text=False):\n",
    "    '''\n",
    "        get audio information from text files to split audio into clips\n",
    "        text_dir         : directory containing texts with audio info\n",
    "        get_text         : add text column to info DataFrame\n",
    "        returns: DataFrame\n",
    "        - id (file id)\n",
    "        - clip (clip number)\n",
    "        - start_time (audio file segment start time)\n",
    "        - end_time   (audio file segment end time)\n",
    "        - len (audio clip len)\n",
    "    '''\n",
    "    text_files = glob.glob(f\"{text_dir}/*.txt\")\n",
    "    dfs = []\n",
    "    for file in text_files:\n",
    "        with open(file, 'r') as text_file:\n",
    "            lines = text_file.readlines()\n",
    "            clips_info = []\n",
    "            for line in lines:\n",
    "                line_info = {}\n",
    "                split_line = line.split('___')\n",
    "                line_info['id'] = split_line[0]\n",
    "                line_info['clip'] = int(split_line[1])\n",
    "                line_info['start_time'] = round(abs(float(split_line[2])) ,3)\n",
    "                line_info['end_time'] = round(float(split_line[3]), 3)\n",
    "                line_info['len'] = \\\n",
    "                    line_info['end_time'] - line_info['start_time']\n",
    "\n",
    "                if get_text:\n",
    "                    line_info['text'] = split_line[4]\n",
    "                \n",
    "                clips_info.append(line_info)\n",
    "        dfs.append(pd.DataFrame(clips_info))\n",
    "    dfs = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_clips_info(labels_dir, text_dir,\n",
    "        get_text=False, show_progress=True):\n",
    "    '''\n",
    "        labels_dir       : directory containing labels\n",
    "        text_dir         : directory containing text files and clip info\n",
    "        get_text         : add text column to info DataFrame\n",
    "        returns          : DataFrame containing:\n",
    "                           id         : file id\n",
    "                           clip       : audio clip/line number\n",
    "                           start_time : audio clip start time\n",
    "                           end time   : audio clip end time\n",
    "                           len        : audio clip len\n",
    "                           text       : text if get_text == True\n",
    "                    clips_not_in_text (labeled_clips)\n",
    "    '''\n",
    "\n",
    "    stime = time()\n",
    "    print(\"Recherche des ids et no. de clips annotés   ...\")\n",
    "    labeled_clips = get_labeled_clips(labels_dir)\n",
    "    print(\"Extraction des infos audio (début/fin)      ...\")\n",
    "    clips_info = get_clips_info_from_text(text_dir, get_text)\n",
    "\n",
    "    labeled_clips_info = []\n",
    "    clips_not_in_text = []\n",
    "    print(\"Selection de l'info audio des clips annotés ...\")\n",
    "    num_files = len(labeled_clips)\n",
    "    files_processed = 0\n",
    "    for i, clips in labeled_clips.items():\n",
    "        mask_id = clips_info['id'] == i\n",
    "        for clip in clips:\n",
    "            mask_clip = clips_info['clip'] == clip\n",
    "            clip_info = {}\n",
    "            clip_info['id'] = i\n",
    "            clip_info['clip'] = clip\n",
    "            try:\n",
    "                # if text with id contains clip, add info to clip_info\n",
    "                len(clips_info[(mask_id) & (mask_clip)].index) == 1\n",
    "                clip_info['start_time'] = \\\n",
    "                        clips_info[(mask_id) & (mask_clip)]['start_time'].values[0]\n",
    "                clip_info['end_time'] = \\\n",
    "                        clips_info[(mask_id) & (mask_clip)]['end_time'].values[0]\n",
    "                clip_info['len'] = \\\n",
    "                        clips_info[(mask_id) & (mask_clip)]['len'].values[0]\n",
    "                if get_text:\n",
    "                        clip_info['text'] = \\\n",
    "                            clips_info[(mask_id) & (mask_clip)]['text'].values[0]\n",
    "                labeled_clips_info.append(clip_info)\n",
    "            except:\n",
    "                # if no clip in text add id and clip to errors\n",
    "                clips_not_in_text.append(clip_info)\n",
    "\n",
    "        if show_progress:\n",
    "            files_processed += 1\n",
    "            if files_processed % 10 == 0:\n",
    "                print('.', end = '')\n",
    "                if files_processed % 500 == 0:\n",
    "                    print(f\" {files_processed} de {num_files} fichiers\")\n",
    "    print(\"\\nTemps d'exécution: \",\n",
    "            f\"{timedelta(seconds = round(time() - stime))} (h:mm:ss)\")\n",
    "    clips_not_in_text = pd.DataFrame(clips_not_in_text)\n",
    "    labeled_clips_info = pd.DataFrame(labeled_clips_info)\n",
    "    print(f\"\\n{labeled_clips_info.shape[0]} clips annotés\")\n",
    "    print(clips_not_in_text.shape[0],\n",
    "        \"clips annotés sans info audio\")\n",
    "    return labeled_clips_info, clips_not_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f3f243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062 rows dropped\n",
      "18319 grouped labels\n",
      "18063 labels for sentiment with audio\n",
      "\n",
      "                none  positive  negative\n",
      "id                                      \n",
      "--qXJuDtHPw_5      0         1         0\n",
      "-3g5yACwYnA_10     0         1         0\n",
      "-3g5yACwYnA_13     0         1         0\n",
      "-3g5yACwYnA_3      1         0         0\n",
      "-3g5yACwYnA_4      1         0         0\n"
     ]
    }
   ],
   "source": [
    "sentiment_labels = get_labels_sentiment(labels_dir, audio_out_dir)\n",
    "print(\"\")\n",
    "print(sentiment_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b730e",
   "metadata": {},
   "source": [
    "# Extract audio features (median on 4 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcb46ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_median(audio_file, len_secs=3,\n",
    "                           n_mfccs=40, rms=False, zrc=False):\n",
    "\n",
    "    import librosa\n",
    "    samples, srate = \\\n",
    "        librosa.load(audio_file, sr=None)\n",
    "    if srate != 16000:\n",
    "        samples, srate = \\\n",
    "            librosa.load(audio_file, sr=16000)\n",
    "    \n",
    "    if len_secs != 'full':\n",
    "        # keep end of samples of len_secs\n",
    "        num_samples = srate * len_secs\n",
    "        if num_samples > len(samples):\n",
    "            samples = samples[-num_samples:]\n",
    "    \n",
    "    audio_features = None\n",
    "    feature_names = []\n",
    "    if rms:\n",
    "        feature_names += ['rms']\n",
    "        audio_features = \\\n",
    "            np.median(librosa.feature.rms(y=samples).T, axis=0)\n",
    "    if zrc:\n",
    "        feature_names += ['zrc']\n",
    "        zrc = \\\n",
    "            np.median(librosa.feature.zero_crossing_rate(y=samples).T,\n",
    "                    axis=0)\n",
    "        if isinstance(audio_features, np.ndarray):\n",
    "            audio_features = np.append(audio_features, zrc)\n",
    "        else:\n",
    "            audio_features = zrc\n",
    "    feature_names += ['mfcc_' + str(x) for x in range(1, n_mfccs + 1)]\n",
    "    S = librosa.feature.melspectrogram(y=samples,\n",
    "                                   sr=srate, n_mels=64, #128,\n",
    "                                   fmax=8000, hop_length=512)\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=n_mfccs)\n",
    "    mfccs = np.median(mfccs, axis=1)\n",
    "    if isinstance(audio_features, np.ndarray):\n",
    "        audio_features = np.append(audio_features, mfccs)\n",
    "    else:\n",
    "        audio_features = mfccs\n",
    "    return audio_features, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "47562537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_mean(audio_file, len_secs=3,\n",
    "                           n_mfccs=40, rms=False, zrc=False):\n",
    "\n",
    "    import librosa\n",
    "    samples, srate = \\\n",
    "        librosa.load(audio_file, sr=None)\n",
    "    if srate != 16000:\n",
    "        samples, srate = \\\n",
    "            librosa.load(audio_file, sr=16000)\n",
    "    \n",
    "    if len_secs != 'full':\n",
    "        # keep end of samples of len_secs\n",
    "        num_samples = srate * len_secs\n",
    "        if num_samples > len(samples):\n",
    "            samples = samples[-num_samples:]\n",
    "    \n",
    "    audio_features = None\n",
    "    feature_names = []\n",
    "    if rms:\n",
    "        feature_names += ['rms']\n",
    "        audio_features = \\\n",
    "            np.mean(librosa.feature.rms(y=samples).T, axis=0)\n",
    "    if zrc:\n",
    "        feature_names += ['zrc']\n",
    "        zrc = \\\n",
    "            np.mean(librosa.feature.zero_crossing_rate(y=samples).T,\n",
    "                    axis=0)\n",
    "        if isinstance(audio_features, np.ndarray):\n",
    "            audio_features = np.append(audio_features, zrc)\n",
    "        else:\n",
    "            audio_features = zrc\n",
    "    \n",
    "    feature_names += ['mfcc_' + str(x) for x in range(1, n_mfccs + 1)]\n",
    "    S = librosa.feature.melspectrogram(y=samples,\n",
    "                                   sr=srate, n_mels=64, #128,\n",
    "                                   fmax=8000, hop_length=512)\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=n_mfccs)\n",
    "    mfccs = np.mean(mfccs, axis=1)\n",
    "    if isinstance(audio_features, np.ndarray):\n",
    "        audio_features = np.append(audio_features, mfccs)\n",
    "    else:\n",
    "        audio_features = mfccs\n",
    "    return audio_features, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d4bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dir(audio_dir, file_names=None,\n",
    "                                    agg='median', len_secs='full',\n",
    "                                    n_mfccs=20, rms=False, zrc=False,\n",
    "                                    show_progress=True):\n",
    "    not_files = []\n",
    "    audio_features = {}\n",
    "    stime = time.time()\n",
    "    cnt = 0\n",
    "    if file_names is None:\n",
    "        file_names = glob.glob(f\"{audio_dir}/*.wav\")\n",
    "    else:\n",
    "        file_names = [audio_dir + '/' + f + '.wav' for f in file_names]\n",
    "    num_files = len(file_names)\n",
    "\n",
    "    for i, f in enumerate(file_names):\n",
    "        if agg == 'median':\n",
    "            clip_features, fnames = \\\n",
    "                extract_features_median(f, len_secs, n_mfccs, rms, zrc)\n",
    "                # # extract_audio_features_median(audio_dir + '/' + f,\n",
    "        else:\n",
    "            clip_features, fnames = \\\n",
    "                extract_features_mean(f, len_secs, n_mfccs, rms, zrc)\n",
    "                # extract_audio_features_mean(audio_dir + '/' + f,\n",
    "        # audio_features[f.rsplit('.', maxsplit = 1)[0]] = clip_features\n",
    "        # check new split !!!!!!\n",
    "        clip_id = f.rsplit('.', maxsplit = 1)[0].rsplit('/', maxsplit = 1)[-1]\n",
    "        audio_features[clip_id] = clip_features\n",
    "        # audio_features[f.rsplit('.', maxsplit = 1)[0]] = clip_features\n",
    "        # else:\n",
    "        #    not_files.append(f)\n",
    "            # print(f\"{f} not in audio_dir\")\n",
    "\n",
    "        if show_progress:\n",
    "            if i % 10 == 0 and i != 0:\n",
    "                print('.', end = '')\n",
    "                if i % 500 == 0:\n",
    "                    print(f\" {i} de {num_files} fichiers\")\n",
    "\n",
    "    audio_features = pd.DataFrame(audio_features).T\n",
    "    audio_features.columns = fnames #['mfcc_' + str(x) for x in range(1, n_mfccs + 1)]\n",
    "    etime = time.time() # ptime()\n",
    "    proc_time = timedelta(seconds = round(etime - stime))\n",
    "    print(f\"\\n\\n{audio_features.shape[0]} fichiers extraits: {proc_time} (h:mm:ss)\")\n",
    "    return audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32e568d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................. 500 de 23259 fichiers\n",
      ".................................................. 1000 de 23259 fichiers\n",
      ".................................................. 1500 de 23259 fichiers\n",
      ".................................................. 2000 de 23259 fichiers\n",
      ".................................................. 2500 de 23259 fichiers\n",
      ".................................................. 3000 de 23259 fichiers\n",
      ".................................................. 3500 de 23259 fichiers\n",
      ".................................................. 4000 de 23259 fichiers\n",
      ".................................................. 4500 de 23259 fichiers\n",
      ".................................................. 5000 de 23259 fichiers\n",
      ".................................................. 5500 de 23259 fichiers\n",
      ".................................................. 6000 de 23259 fichiers\n",
      ".................................................. 6500 de 23259 fichiers\n",
      ".................................................. 7000 de 23259 fichiers\n",
      ".................................................. 7500 de 23259 fichiers\n",
      ".................................................. 8000 de 23259 fichiers\n",
      ".................................................. 8500 de 23259 fichiers\n",
      ".................................................. 9000 de 23259 fichiers\n",
      ".................................................. 9500 de 23259 fichiers\n",
      ".................................................. 10000 de 23259 fichiers\n",
      ".................................................. 10500 de 23259 fichiers\n",
      ".................................................. 11000 de 23259 fichiers\n",
      ".................................................. 11500 de 23259 fichiers\n",
      ".................................................. 12000 de 23259 fichiers\n",
      ".................................................. 12500 de 23259 fichiers\n",
      ".................................................. 13000 de 23259 fichiers\n",
      ".................................................. 13500 de 23259 fichiers\n",
      ".................................................. 14000 de 23259 fichiers\n",
      ".................................................. 14500 de 23259 fichiers\n",
      ".................................................. 15000 de 23259 fichiers\n",
      ".................................................. 15500 de 23259 fichiers\n",
      ".................................................. 16000 de 23259 fichiers\n",
      ".................................................. 16500 de 23259 fichiers\n",
      ".................................................. 17000 de 23259 fichiers\n",
      ".................................................. 17500 de 23259 fichiers\n",
      ".................................................. 18000 de 23259 fichiers\n",
      "............"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graymo/.cache/pypoetry/virtualenvs/emotion-eq9CsLJl-py3.8/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1920\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................... 18500 de 23259 fichiers\n",
      ".................................................. 19000 de 23259 fichiers\n",
      ".................................................. 19500 de 23259 fichiers\n",
      ".................................................. 20000 de 23259 fichiers\n",
      ".................................................. 20500 de 23259 fichiers\n",
      ".................................................. 21000 de 23259 fichiers\n",
      ".................................................. 21500 de 23259 fichiers\n",
      ".................................................. 22000 de 23259 fichiers\n",
      ".................................................. 22500 de 23259 fichiers\n",
      ".................................................. 23000 de 23259 fichiers\n",
      ".........................\n",
      "\n",
      "23259 fichiers extraits: 0:04:32 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "mfcc40_3sec_median = \\\n",
    "    extract_features_from_dir(audio_out_dir, file_names=None,\n",
    "                                    agg='median', len_secs=7,\n",
    "                                    n_mfccs=40, rms=False, zrc=False,\n",
    "                                    show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a5a1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc40_7sec_median.to_csv(\"./mfcc40_7sec_median.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8b886279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_31</th>\n",
       "      <th>mfcc_32</th>\n",
       "      <th>mfcc_33</th>\n",
       "      <th>mfcc_34</th>\n",
       "      <th>mfcc_35</th>\n",
       "      <th>mfcc_36</th>\n",
       "      <th>mfcc_37</th>\n",
       "      <th>mfcc_38</th>\n",
       "      <th>mfcc_39</th>\n",
       "      <th>mfcc_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MPRqaQqrd9Y_7</th>\n",
       "      <td>-238.47780</td>\n",
       "      <td>116.48294</td>\n",
       "      <td>-16.343117</td>\n",
       "      <td>13.451738</td>\n",
       "      <td>-20.161373</td>\n",
       "      <td>-10.331965</td>\n",
       "      <td>-14.032530</td>\n",
       "      <td>3.187353</td>\n",
       "      <td>-8.783220</td>\n",
       "      <td>-4.770639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175206</td>\n",
       "      <td>-0.482796</td>\n",
       "      <td>1.425903</td>\n",
       "      <td>1.884764</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.529950</td>\n",
       "      <td>1.037738</td>\n",
       "      <td>1.994728</td>\n",
       "      <td>-0.325253</td>\n",
       "      <td>-1.274733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UlTJmndbGHM_4</th>\n",
       "      <td>-53.42596</td>\n",
       "      <td>94.49222</td>\n",
       "      <td>-19.986244</td>\n",
       "      <td>47.588350</td>\n",
       "      <td>-21.567050</td>\n",
       "      <td>40.110077</td>\n",
       "      <td>-9.876991</td>\n",
       "      <td>21.592289</td>\n",
       "      <td>-3.903989</td>\n",
       "      <td>11.753240</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.387760</td>\n",
       "      <td>-0.199772</td>\n",
       "      <td>-1.833252</td>\n",
       "      <td>-1.971496</td>\n",
       "      <td>0.220655</td>\n",
       "      <td>-1.211483</td>\n",
       "      <td>1.755036</td>\n",
       "      <td>-1.856162</td>\n",
       "      <td>2.457587</td>\n",
       "      <td>-0.118698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hjBQmIWiWgw_2</th>\n",
       "      <td>-247.95389</td>\n",
       "      <td>101.13844</td>\n",
       "      <td>-9.910642</td>\n",
       "      <td>7.709038</td>\n",
       "      <td>-13.915911</td>\n",
       "      <td>10.742346</td>\n",
       "      <td>-22.425343</td>\n",
       "      <td>-8.783762</td>\n",
       "      <td>-15.749350</td>\n",
       "      <td>-6.562918</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.128196</td>\n",
       "      <td>-3.294880</td>\n",
       "      <td>-1.202057</td>\n",
       "      <td>-2.194178</td>\n",
       "      <td>-1.391237</td>\n",
       "      <td>-2.352279</td>\n",
       "      <td>-0.927700</td>\n",
       "      <td>-2.602970</td>\n",
       "      <td>-1.094968</td>\n",
       "      <td>-1.410288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9zWeMrfr-l0_0</th>\n",
       "      <td>-227.37321</td>\n",
       "      <td>89.07364</td>\n",
       "      <td>-9.827379</td>\n",
       "      <td>26.472038</td>\n",
       "      <td>2.726988</td>\n",
       "      <td>1.796814</td>\n",
       "      <td>-16.575570</td>\n",
       "      <td>8.506326</td>\n",
       "      <td>-8.254383</td>\n",
       "      <td>-6.067927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133548</td>\n",
       "      <td>-0.343467</td>\n",
       "      <td>-0.757080</td>\n",
       "      <td>-0.810546</td>\n",
       "      <td>-0.412276</td>\n",
       "      <td>-1.497693</td>\n",
       "      <td>-0.009953</td>\n",
       "      <td>-1.921595</td>\n",
       "      <td>-1.485501</td>\n",
       "      <td>-1.057941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31197_2</th>\n",
       "      <td>-219.16013</td>\n",
       "      <td>122.94565</td>\n",
       "      <td>-42.745243</td>\n",
       "      <td>51.231842</td>\n",
       "      <td>8.988421</td>\n",
       "      <td>-1.754196</td>\n",
       "      <td>27.006640</td>\n",
       "      <td>-5.793803</td>\n",
       "      <td>10.785469</td>\n",
       "      <td>6.574906</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.564412</td>\n",
       "      <td>-0.184192</td>\n",
       "      <td>-1.412041</td>\n",
       "      <td>-0.797373</td>\n",
       "      <td>0.196932</td>\n",
       "      <td>-2.414317</td>\n",
       "      <td>0.634682</td>\n",
       "      <td>-0.541945</td>\n",
       "      <td>-0.924508</td>\n",
       "      <td>-0.020378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mfcc_1     mfcc_2     mfcc_3     mfcc_4     mfcc_5  \\\n",
       "MPRqaQqrd9Y_7 -238.47780  116.48294 -16.343117  13.451738 -20.161373   \n",
       "UlTJmndbGHM_4  -53.42596   94.49222 -19.986244  47.588350 -21.567050   \n",
       "hjBQmIWiWgw_2 -247.95389  101.13844  -9.910642   7.709038 -13.915911   \n",
       "9zWeMrfr-l0_0 -227.37321   89.07364  -9.827379  26.472038   2.726988   \n",
       "31197_2       -219.16013  122.94565 -42.745243  51.231842   8.988421   \n",
       "\n",
       "                  mfcc_6     mfcc_7     mfcc_8     mfcc_9    mfcc_10  ...  \\\n",
       "MPRqaQqrd9Y_7 -10.331965 -14.032530   3.187353  -8.783220  -4.770639  ...   \n",
       "UlTJmndbGHM_4  40.110077  -9.876991  21.592289  -3.903989  11.753240  ...   \n",
       "hjBQmIWiWgw_2  10.742346 -22.425343  -8.783762 -15.749350  -6.562918  ...   \n",
       "9zWeMrfr-l0_0   1.796814 -16.575570   8.506326  -8.254383  -6.067927  ...   \n",
       "31197_2        -1.754196  27.006640  -5.793803  10.785469   6.574906  ...   \n",
       "\n",
       "                mfcc_31   mfcc_32   mfcc_33   mfcc_34   mfcc_35   mfcc_36  \\\n",
       "MPRqaQqrd9Y_7  0.175206 -0.482796  1.425903  1.884764  0.493000  0.529950   \n",
       "UlTJmndbGHM_4 -1.387760 -0.199772 -1.833252 -1.971496  0.220655 -1.211483   \n",
       "hjBQmIWiWgw_2 -3.128196 -3.294880 -1.202057 -2.194178 -1.391237 -2.352279   \n",
       "9zWeMrfr-l0_0 -0.133548 -0.343467 -0.757080 -0.810546 -0.412276 -1.497693   \n",
       "31197_2       -3.564412 -0.184192 -1.412041 -0.797373  0.196932 -2.414317   \n",
       "\n",
       "                mfcc_37   mfcc_38   mfcc_39   mfcc_40  \n",
       "MPRqaQqrd9Y_7  1.037738  1.994728 -0.325253 -1.274733  \n",
       "UlTJmndbGHM_4  1.755036 -1.856162  2.457587 -0.118698  \n",
       "hjBQmIWiWgw_2 -0.927700 -2.602970 -1.094968 -1.410288  \n",
       "9zWeMrfr-l0_0 -0.009953 -1.921595 -1.485501 -1.057941  \n",
       "31197_2        0.634682 -0.541945 -0.924508 -0.020378  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc40_3sec_median = pd.read_csv(\"./mfcc40_median_3sec.csv\", index_col=0)\n",
    "mfcc40_3sec_median.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "72081e06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................. 500 de 23259 fichiers\n",
      ".................................................. 1000 de 23259 fichiers\n",
      ".................................................. 1500 de 23259 fichiers\n",
      ".................................................. 2000 de 23259 fichiers\n",
      ".................................................. 2500 de 23259 fichiers\n",
      ".................................................. 3000 de 23259 fichiers\n",
      ".................................................. 3500 de 23259 fichiers\n",
      ".................................................. 4000 de 23259 fichiers\n",
      ".................................................. 4500 de 23259 fichiers\n",
      ".................................................. 5000 de 23259 fichiers\n",
      ".................................................. 5500 de 23259 fichiers\n",
      ".................................................. 6000 de 23259 fichiers\n",
      ".................................................. 6500 de 23259 fichiers\n",
      ".................................................. 7000 de 23259 fichiers\n",
      ".................................................. 7500 de 23259 fichiers\n",
      ".................................................. 8000 de 23259 fichiers\n",
      ".................................................. 8500 de 23259 fichiers\n",
      ".................................................. 9000 de 23259 fichiers\n",
      ".................................................. 9500 de 23259 fichiers\n",
      ".................................................. 10000 de 23259 fichiers\n",
      ".................................................. 10500 de 23259 fichiers\n",
      ".................................................. 11000 de 23259 fichiers\n",
      ".................................................. 11500 de 23259 fichiers\n",
      ".................................................. 12000 de 23259 fichiers\n",
      ".................................................. 12500 de 23259 fichiers\n",
      ".................................................. 13000 de 23259 fichiers\n",
      ".................................................. 13500 de 23259 fichiers\n",
      ".................................................. 14000 de 23259 fichiers\n",
      ".................................................. 14500 de 23259 fichiers\n",
      ".................................................. 15000 de 23259 fichiers\n",
      ".................................................. 15500 de 23259 fichiers\n",
      ".................................................. 16000 de 23259 fichiers\n",
      ".................................................. 16500 de 23259 fichiers\n",
      ".................................................. 17000 de 23259 fichiers\n",
      ".................................................. 17500 de 23259 fichiers\n",
      ".................................................. 18000 de 23259 fichiers\n",
      "..........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graymo/.cache/pypoetry/virtualenvs/emotion-eq9CsLJl-py3.8/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1920\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................... 18500 de 23259 fichiers\n",
      ".................................................. 19000 de 23259 fichiers\n",
      ".................................................. 19500 de 23259 fichiers\n",
      ".................................................. 20000 de 23259 fichiers\n",
      ".................................................. 20500 de 23259 fichiers\n",
      ".................................................. 21000 de 23259 fichiers\n",
      ".................................................. 21500 de 23259 fichiers\n",
      ".................................................. 22000 de 23259 fichiers\n",
      ".................................................. 22500 de 23259 fichiers\n",
      ".................................................. 23000 de 23259 fichiers\n",
      ".........................\n",
      "\n",
      "23259 fichiers extraits: 0:04:44 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "mfcc40_5sec_median = \\\n",
    "    extract_audio_features_from_dir(audio_out_dir, file_names=None,\n",
    "                                    agg='median', len_secs=5,\n",
    "                                    n_mfccs=40, rms=False, zrc=False,\n",
    "                                    show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6cbdb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc40_5sec_median = mfcc40_5sec_median_new\n",
    "mfcc40_5sec_median.to_csv(\"./mfcc40_5sec_median.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "63309956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................. 500 de 23259 fichiers\n",
      ".................................................. 1000 de 23259 fichiers\n",
      ".................................................. 1500 de 23259 fichiers\n",
      ".................................................. 2000 de 23259 fichiers\n",
      ".................................................. 2500 de 23259 fichiers\n",
      ".................................................. 3000 de 23259 fichiers\n",
      ".................................................. 3500 de 23259 fichiers\n",
      ".................................................. 4000 de 23259 fichiers\n",
      ".................................................. 4500 de 23259 fichiers\n",
      ".................................................. 5000 de 23259 fichiers\n",
      ".................................................. 5500 de 23259 fichiers\n",
      ".................................................. 6000 de 23259 fichiers\n",
      ".................................................. 6500 de 23259 fichiers\n",
      ".................................................. 7000 de 23259 fichiers\n",
      ".................................................. 7500 de 23259 fichiers\n",
      ".................................................. 8000 de 23259 fichiers\n",
      ".................................................. 8500 de 23259 fichiers\n",
      ".................................................. 9000 de 23259 fichiers\n",
      ".................................................. 9500 de 23259 fichiers\n",
      ".................................................. 10000 de 23259 fichiers\n",
      ".................................................. 10500 de 23259 fichiers\n",
      ".................................................. 11000 de 23259 fichiers\n",
      ".................................................. 11500 de 23259 fichiers\n",
      ".................................................. 12000 de 23259 fichiers\n",
      ".................................................. 12500 de 23259 fichiers\n",
      ".................................................. 13000 de 23259 fichiers\n",
      ".................................................. 13500 de 23259 fichiers\n",
      ".................................................. 14000 de 23259 fichiers\n",
      ".................................................. 14500 de 23259 fichiers\n",
      ".................................................. 15000 de 23259 fichiers\n",
      ".................................................. 15500 de 23259 fichiers\n",
      ".................................................. 16000 de 23259 fichiers\n",
      ".................................................. 16500 de 23259 fichiers\n",
      ".................................................. 17000 de 23259 fichiers\n",
      ".................................................. 17500 de 23259 fichiers\n",
      ".................................................. 18000 de 23259 fichiers\n",
      "............"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graymo/.cache/pypoetry/virtualenvs/emotion-eq9CsLJl-py3.8/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1920\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................... 18500 de 23259 fichiers\n",
      ".................................................. 19000 de 23259 fichiers\n",
      ".................................................. 19500 de 23259 fichiers\n",
      ".................................................. 20000 de 23259 fichiers\n",
      ".................................................. 20500 de 23259 fichiers\n",
      ".................................................. 21000 de 23259 fichiers\n",
      ".................................................. 21500 de 23259 fichiers\n",
      ".................................................. 22000 de 23259 fichiers\n",
      ".................................................. 22500 de 23259 fichiers\n",
      ".................................................. 23000 de 23259 fichiers\n",
      ".........................\n",
      "\n",
      "23259 fichiers extraits: 0:04:45 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "mfcc40_5sec_mean = \\\n",
    "    extract_audio_features_from_dir(audio_out_dir, file_names=None,\n",
    "                                    agg='mean', len_secs=5,\n",
    "                                    n_mfccs=40, rms=False, zrc=False,\n",
    "                                    show_progress=True)\n",
    "mfcc40_5sec_mean.to_csv(\"./mfcc40_5sec_mean.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4a3fbb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................. 500 de 23259 fichiers\n",
      ".................................................. 1000 de 23259 fichiers\n",
      ".................................................. 1500 de 23259 fichiers\n",
      ".................................................. 2000 de 23259 fichiers\n",
      ".................................................. 2500 de 23259 fichiers\n",
      ".................................................. 3000 de 23259 fichiers\n",
      ".................................................. 3500 de 23259 fichiers\n",
      ".................................................. 4000 de 23259 fichiers\n",
      ".................................................. 4500 de 23259 fichiers\n",
      ".................................................. 5000 de 23259 fichiers\n",
      ".................................................. 5500 de 23259 fichiers\n",
      ".................................................. 6000 de 23259 fichiers\n",
      ".................................................. 6500 de 23259 fichiers\n",
      ".................................................. 7000 de 23259 fichiers\n",
      ".................................................. 7500 de 23259 fichiers\n",
      ".................................................. 8000 de 23259 fichiers\n",
      ".................................................. 8500 de 23259 fichiers\n",
      ".................................................. 9000 de 23259 fichiers\n",
      ".................................................. 9500 de 23259 fichiers\n",
      ".................................................. 10000 de 23259 fichiers\n",
      ".................................................. 10500 de 23259 fichiers\n",
      ".................................................. 11000 de 23259 fichiers\n",
      ".................................................. 11500 de 23259 fichiers\n",
      ".................................................. 12000 de 23259 fichiers\n",
      ".................................................. 12500 de 23259 fichiers\n",
      ".................................................. 13000 de 23259 fichiers\n",
      ".................................................. 13500 de 23259 fichiers\n",
      ".................................................. 14000 de 23259 fichiers\n",
      ".................................................. 14500 de 23259 fichiers\n",
      ".................................................. 15000 de 23259 fichiers\n",
      ".................................................. 15500 de 23259 fichiers\n",
      ".................................................. 16000 de 23259 fichiers\n",
      ".................................................. 16500 de 23259 fichiers\n",
      ".................................................. 17000 de 23259 fichiers\n",
      ".................................................. 17500 de 23259 fichiers\n",
      ".................................................. 18000 de 23259 fichiers\n",
      "............"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graymo/.cache/pypoetry/virtualenvs/emotion-eq9CsLJl-py3.8/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1920\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................... 18500 de 23259 fichiers\n",
      ".................................................. 19000 de 23259 fichiers\n",
      ".................................................. 19500 de 23259 fichiers\n",
      ".................................................. 20000 de 23259 fichiers\n",
      ".................................................. 20500 de 23259 fichiers\n",
      ".................................................. 21000 de 23259 fichiers\n",
      ".................................................. 21500 de 23259 fichiers\n",
      ".................................................. 22000 de 23259 fichiers\n",
      ".................................................. 22500 de 23259 fichiers\n",
      ".................................................. 23000 de 23259 fichiers\n",
      ".........................\n",
      "\n",
      "23259 fichiers extraits: 0:04:39 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "mfcc40_3sec_mean = \\\n",
    "    extract_audio_features_from_dir(audio_out_dir, file_names=None,\n",
    "                                    agg='mean', len_secs=3,\n",
    "                                    n_mfccs=40, rms=False, zrc=False,\n",
    "                                    show_progress=True)\n",
    "mfcc40_3sec_mean.to_csv(\"./mfcc40_3sec_mean.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fa0e2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_3sec_median_new.to_csv(\"./mfcc40_3sec_median.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aae0b8",
   "metadata": {},
   "source": [
    "# Align features with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "711a7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(in_features, in_labels, test_size=0.2):\n",
    "    labels = in_labels.copy()\n",
    "    features = in_features.copy().reindex(labels.index)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(features, labels, test_size=0.2,\n",
    "                         random_state=100,\n",
    "                         stratify = labels.values.argmax(axis=1))\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"y_test.shape: {y_test.shape}\")\n",
    "    print(\"\\ntraining label count:\")\n",
    "    print(y_train.sum(axis=0))\n",
    "    print(\"\\ntest label count:\")\n",
    "    print(y_test.sum(axis=0))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3e1da9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaled_datasets(in_features, in_labels, val_size=0.2, test_size=0.1):\n",
    "    labels = in_labels.copy()\n",
    "    features = in_features.copy().reindex(labels.index)\n",
    "    X_dev, X_test, y_dev, y_test = \\\n",
    "        train_test_split(features, labels, test_size=test_size,\n",
    "                         random_state=100,\n",
    "                         stratify = labels.values.argmax(axis=1))\n",
    "    X_train, X_val, y_train, y_val = \\\n",
    "        train_test_split(X_dev, y_dev, test_size=val_size,\n",
    "                         random_state=100,\n",
    "                         stratify = y_dev.values.argmax(axis=1))\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"X_val.shape: {X_val.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"y_val.shape: {y_val.shape}\")\n",
    "    print(f\"y_test.shape: {y_test.shape}\")\n",
    "    \n",
    "    print(\"\\ntraining label count:\")\n",
    "    print(y_train.sum(axis=0))\n",
    "    print(\"\\nvalidation label count:\")\n",
    "    print(y_val.sum(axis=0))\n",
    "    print(\"\\ntest label count:\")\n",
    "    print(y_test.sum(axis=0))\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "110f218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics_per_class(y_true, y_pred, classes=None):\n",
    "    \n",
    "    if len(y_true.shape) > 1:\n",
    "        conf_mtx = pd.DataFrame(\n",
    "                            confusion_matrix(\n",
    "                                y_true.values.argmax(axis=1),\n",
    "                                y_pred.argmax(axis=1)\n",
    "                            )\n",
    "                        )\n",
    "    else:\n",
    "        conf_mtx = pd.DataFrame(\n",
    "                            confusion_matrix(\n",
    "                                y_true,\n",
    "                                y_pred\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    if classes != None:\n",
    "        conf_mtx.index = classes\n",
    "        conf_mtx.columns = classes\n",
    "    else:\n",
    "        classes = sorted(list(y_true.unique()))\n",
    "        conf_mtx.index = classes\n",
    "        conf_mtx.columns = classes\n",
    "\n",
    "    class_metrics = {}\n",
    "    for c in classes:\n",
    "        metrics = {}\n",
    "        metrics['precision'] = \\\n",
    "            round(conf_mtx.loc[c, c] / conf_mtx.loc[:, c].sum(), 3)\n",
    "        metrics['recall'] = \\\n",
    "            round(conf_mtx.loc[c, c] / conf_mtx.loc[c, :].sum(), 3)\n",
    "        metrics['f1'] = \\\n",
    "            round(2 * (metrics['precision'] * metrics['recall'])/\n",
    "                  (metrics['precision'] + metrics['recall']), 3)\n",
    "        class_metrics[c] = metrics\n",
    "        # metrics\n",
    "    class_metrics = pd.DataFrame(class_metrics)\n",
    "    macro_metrics = class_metrics.sum(axis=1) / 3\n",
    "    class_metrics = class_metrics.T\n",
    "    class_metrics.loc['macro'] = macro_metrics.round(3)\n",
    "    return conf_mtx, class_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8e004e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svc(X_train, y_train, C=5):\n",
    "    gamma='auto'\n",
    "    # C=18 good,\n",
    "    svc = SVC(C=C, kernel='rbf', gamma=gamma, random_state=101)\n",
    "    svc.fit(X_train, y_train.values.argmax(axis=1))\n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4bf98550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_show_metrics(model, X, y, show_confu=False, data_name='data'):\n",
    "    pred = svc_model.predict(X)\n",
    "    print(f\"\\n{data_name} accuracy : \",\n",
    "          round(accuracy_score(y.values.argmax(axis=1), pred),3))\n",
    "\n",
    "    conf_mtx, metrics = \\\n",
    "    calc_metrics_per_class(y.values.argmax(axis=1), pred,\n",
    "                           classes=y.columns.tolist())\n",
    "    if show_confu:\n",
    "        print(\"\")\n",
    "        print(conf_mtx)\n",
    "    print(\"\")\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d00e907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (14450, 40)\n",
      "X_test.shape: (3613, 40)\n",
      "y_train.shape: (14450, 3)\n",
      "y_test.shape: (3613, 3)\n",
      "\n",
      "training label count:\n",
      "none        5282\n",
      "positive    5522\n",
      "negative    3674\n",
      "dtype: int64\n",
      "\n",
      "test label count:\n",
      "none        1320\n",
      "positive    1380\n",
      "negative     918\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    create_datasets(mfcc40_7sec_median, sentiment_labels)\n",
    "    # create_datasets(rms_mfcc40_7sec_median, sentiment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26ced06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = train_svc(X_train, y_train, C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "20b6ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy :  0.791\n",
      "\n",
      "          precision  recall     f1\n",
      "none          0.791   0.754  0.772\n",
      "positive      0.763   0.855  0.806\n",
      "negative      0.844   0.747  0.793\n",
      "macro         0.799   0.785  0.790\n"
     ]
    }
   ],
   "source": [
    "predict_show_metrics(svc_model, X_train, y_train, data_name='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b5fb3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy :  0.582\n",
      "\n",
      "          precision  recall     f1\n",
      "none          0.536   0.518  0.527\n",
      "positive      0.591   0.665  0.626\n",
      "negative      0.638   0.549  0.590\n",
      "macro         0.588   0.577  0.581\n"
     ]
    }
   ],
   "source": [
    "predict_show_metrics(svc_model, X_test, y_test, data_name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275bfb4",
   "metadata": {},
   "source": [
    "\n",
    "# model 3sec mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "73f21a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (14450, 40)\n",
      "X_test.shape: (3613, 40)\n",
      "y_train.shape: (14450, 3)\n",
      "y_test.shape: (3613, 3)\n",
      "\n",
      "training label count:\n",
      "none        5282\n",
      "positive    5522\n",
      "negative    3674\n",
      "dtype: int64\n",
      "\n",
      "test label count:\n",
      "none        1320\n",
      "positive    1380\n",
      "negative     918\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, scaler = \\\n",
    "    create_datasets(mfcc40_3sec_mean, sentiment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "45770895",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = train_svc(X_train, y_train, C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2d1b2ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy :  0.791\n",
      "\n",
      "          precision  recall     f1\n",
      "none          0.786   0.761  0.773\n",
      "positive      0.769   0.848  0.807\n",
      "negative      0.839   0.749  0.791\n",
      "macro         0.798   0.786  0.790\n"
     ]
    }
   ],
   "source": [
    "predict_show_metrics(svc_model, X_train, y_train, data_name='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "03179554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy :  0.569\n",
      "\n",
      "          precision  recall     f1\n",
      "none          0.520   0.508  0.514\n",
      "positive      0.575   0.649  0.610\n",
      "negative      0.639   0.536  0.583\n",
      "macro         0.578   0.564  0.569\n"
     ]
    }
   ],
   "source": [
    "predict_show_metrics(svc_model, X_test, y_test, data_name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "903846fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>none</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>j1m6ctAgjsM_40</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8eaYvALnJ0o_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28006_20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20LfN8ENbhM_6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202431_5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                none  positive  negative\n",
       "id                                      \n",
       "j1m6ctAgjsM_40     1         0         0\n",
       "8eaYvALnJ0o_2      0         1         0\n",
       "28006_20           0         0         1\n",
       "20LfN8ENbhM_6      0         1         0\n",
       "202431_5           1         0         0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d624cf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-195.52985      92.70075     -24.008392     10.492144     -6.4965787\n",
      "  -18.499443    -17.859005    -13.474919     -8.963863     -7.732952\n",
      "   -9.457983     -3.5309544    -7.2717237    -3.894504     -4.5399246\n",
      "   -6.592246     -1.472745     -6.1299205    -6.881275     -2.304553\n",
      "   -5.336194     -4.8850164    -4.1405487    -3.3099942    -3.8576074\n",
      "   -4.1142683    -2.4667516    -2.9003258    -3.1817105    -1.2571107\n",
      "   -2.089558     -1.6431712    -2.0988235    -1.2071482    -0.34366733\n",
      "   -0.29154432   -0.20354536   -0.28135467    0.36818227    0.25190628]\n"
     ]
    }
   ],
   "source": [
    "test_feats, _ = \\\n",
    "    extract_audio_features_median(f\"{audio_out_dir}/20LfN8ENbhM_6.wav\", len_secs=5,\n",
    "                                  n_mfccs=40, rms=False, zrc=False)\n",
    "print(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "770aa372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_1    -195.529846\n",
      "mfcc_2      92.700752\n",
      "mfcc_3     -24.008392\n",
      "mfcc_4      10.492144\n",
      "mfcc_5      -6.496579\n",
      "mfcc_6     -18.499443\n",
      "mfcc_7     -17.859005\n",
      "mfcc_8     -13.474919\n",
      "mfcc_9      -8.963863\n",
      "mfcc_10     -7.732952\n",
      "mfcc_11     -9.457983\n",
      "mfcc_12     -3.530954\n",
      "mfcc_13     -7.271724\n",
      "mfcc_14     -3.894504\n",
      "mfcc_15     -4.539925\n",
      "mfcc_16     -6.592246\n",
      "mfcc_17     -1.472745\n",
      "mfcc_18     -6.129920\n",
      "mfcc_19     -6.881275\n",
      "mfcc_20     -2.304553\n",
      "mfcc_21     -5.336194\n",
      "mfcc_22     -4.885016\n",
      "mfcc_23     -4.140549\n",
      "mfcc_24     -3.309994\n",
      "mfcc_25     -3.857607\n",
      "mfcc_26     -4.114268\n",
      "mfcc_27     -2.466752\n",
      "mfcc_28     -2.900326\n",
      "mfcc_29     -3.181710\n",
      "mfcc_30     -1.257111\n",
      "mfcc_31     -2.089558\n",
      "mfcc_32     -1.643171\n",
      "mfcc_33     -2.098824\n",
      "mfcc_34     -1.207148\n",
      "mfcc_35     -0.343667\n",
      "mfcc_36     -0.291544\n",
      "mfcc_37     -0.203545\n",
      "mfcc_38     -0.281355\n",
      "mfcc_39      0.368182\n",
      "mfcc_40      0.251906\n",
      "Name: 20LfN8ENbhM_6, dtype: float32\n",
      "[[-0.2896645   0.6766481  -1.152351   -0.4575754  -0.3195462  -1.9685535\n",
      "  -1.6210281  -1.2309034  -1.0862635  -1.0308886  -1.4051404  -0.50712365\n",
      "  -1.1987944  -0.9078019  -0.24081172 -1.6511912   0.3630987  -1.4699783\n",
      "  -1.3912349  -0.33556995 -0.9593447  -1.3448936  -0.8448844  -0.92520195\n",
      "  -0.7698588  -1.4743248  -0.3317656  -0.94053346 -0.88965094 -0.3031006\n",
      "  -0.48135826 -0.56795937 -0.6061121  -0.40276453  0.32796717  0.0843113\n",
      "   0.40916482  0.10481904  0.80823344  0.503568  ]]\n"
     ]
    }
   ],
   "source": [
    "test_feats = mfcc40_3sec_median.loc['20LfN8ENbhM_6']\n",
    "# print(test_feats)\n",
    "test_feats = scaler.transform(test_feats.values.reshape(1, -1))\n",
    "# print(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7e82add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test_pred = svc_model.predict(test_feats)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7571de5",
   "metadata": {},
   "source": [
    "# mfcc40 3sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "014650de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (14450, 40)\n",
      "X_test.shape: (3613, 40)\n",
      "y_train.shape: (14450, 3)\n",
      "y_test.shape: (3613, 3)\n",
      "\n",
      "training label count:\n",
      "none        5282\n",
      "positive    5522\n",
      "negative    3674\n",
      "dtype: int64\n",
      "\n",
      "test label count:\n",
      "none        1320\n",
      "positive    1380\n",
      "negative     918\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, scaler = \\\n",
    "    create_datasets(mfcc_3sec_median_new, sentiment_labels)\n",
    "    # create_datasets(mfcc40_3sec_median, sentiment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "896d03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = train_svc(X_train, y_train, C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "56026857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy :  0.791\n",
      "\n",
      "          precision  recall     f1\n",
      "none          0.791   0.754  0.772\n",
      "positive      0.763   0.855  0.806\n",
      "negative      0.844   0.747  0.793\n",
      "macro         0.799   0.785  0.790\n"
     ]
    }
   ],
   "source": [
    "predict_show_metrics(svc_model, X_train, y_train, data_name='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cbc64a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy :  0.582\n",
      "\n",
      "          precision  recall     f1\n",
      "none          0.536   0.518  0.527\n",
      "positive      0.591   0.665  0.626\n",
      "negative      0.638   0.549  0.590\n",
      "macro         0.588   0.577  0.581\n"
     ]
    }
   ],
   "source": [
    "predict_show_metrics(svc_model, X_test, y_test, data_name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7e0c6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3329506e+02  6.9082504e+01  1.9993027e+00  3.0165579e+01\n",
      "  4.8657122e+00  4.5340462e+00 -4.3247681e+00  5.6679940e+00\n",
      " -2.5897515e+00 -3.5472088e+00 -1.2017125e+00 -3.8753498e+00\n",
      " -5.5836668e+00 -5.5898219e-01 -3.2558935e+00  3.5103457e+00\n",
      " -9.8338270e+00 -4.0746432e-02 -1.6256493e+00  9.0134335e-01\n",
      " -6.0412264e+00 -1.8584248e+00 -3.9652193e+00  8.4362030e-01\n",
      " -7.7901870e-01  8.1869185e-01 -1.8088070e+00  3.5724044e+00\n",
      " -1.7526212e-01 -1.4741180e+00 -4.7781491e-01 -1.6564813e-01\n",
      " -1.7174493e+00  2.1145258e+00 -1.7190773e+00  1.9912972e+00\n",
      " -1.9437352e+00 -1.1604613e+00 -1.1484674e+00 -1.6397709e+00]\n",
      "[[ 0.7635654  -0.26115137  0.48957878  1.1923492   1.0420123   0.9935151\n",
      "   0.37793547  1.665574    0.14429611 -0.11704967  0.4874705  -0.54466844\n",
      "  -0.6914352  -0.0087396   0.16978696  1.4739904  -2.3575652   0.5895076\n",
      "   0.5527696   0.7868876  -1.1900071  -0.14027564 -0.77462804  0.75580704\n",
      "   0.42126012  0.63187295 -0.13639873  1.7592795   0.32865947 -0.49446487\n",
      "   0.15859684  0.01109877 -0.48814556  1.019734   -0.56195587  1.0543675\n",
      "  -0.7261137  -0.51505524 -0.31435838 -0.82703394]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test_positive, _ = \\\n",
    "    extract_audio_features_mean(\"../../positive_test.wav\", len_secs=3,\n",
    "                                  n_mfccs=40, rms=False, zrc=False)\n",
    "print(test_positive)\n",
    "test_positive = scaler.transform(test_positive.reshape(1, -1))\n",
    "print(test_positive)\n",
    "test_positive_pred = svc_model.predict(test_positive)\n",
    "print(test_positive_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d08318b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emotion.models.audio_model import AudioModel\n",
    "import emotion.models.audio_model as audio_model\n",
    "import emotion.models.audio_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ed11ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'emotion.models.audio_model' from '/home/graymo/devl/bdeb/a62/emotion/emotion/models/audio_model.py'>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(emotion.models.audio_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a0f25785",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [298]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t_audio_model \u001b[38;5;241m=\u001b[39m \u001b[43memotion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudioModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devl/bdeb/a62/emotion/emotion/models/audio_model.py:18\u001b[0m, in \u001b[0;36mAudioModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(MODEL, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SCALER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scaler \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "t_audio_model = emotion.models.audio_model.AudioModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f1a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "626cf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1cf0a00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision_function_shape': 'ovr',\n",
       " 'break_ties': False,\n",
       " 'kernel': 'rbf',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'coef0': 0.0,\n",
       " 'tol': 0.001,\n",
       " 'C': 5,\n",
       " 'nu': 0.0,\n",
       " 'epsilon': 0.0,\n",
       " 'shrinking': True,\n",
       " 'probability': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'verbose': False,\n",
       " 'max_iter': -1,\n",
       " 'random_state': 101,\n",
       " '_sparse': False,\n",
       " 'n_features_in_': 40,\n",
       " 'class_weight_': array([1., 1., 1.]),\n",
       " 'classes_': array([0, 1, 2]),\n",
       " '_gamma': 0.025,\n",
       " 'support_': array([    2,     7,    10, ..., 14441, 14442, 14449], dtype=int32),\n",
       " 'support_vectors_': array([[-3.39125633e-01, -1.07917376e-01,  2.02631444e-01, ...,\n",
       "         -4.16145623e-01, -1.00107908e+00, -1.09846246e+00],\n",
       "        [ 4.94197726e-01,  3.10632288e-01, -1.62518597e+00, ...,\n",
       "          6.52225912e-01,  3.35251570e-01,  6.16763420e-02],\n",
       "        [-3.32404733e+00, -1.46636404e-02,  1.52493520e-02, ...,\n",
       "         -1.52940893e+00, -6.08805478e-01, -1.80887890e+00],\n",
       "        ...,\n",
       "        [ 5.98988950e-01, -1.94819361e-01, -1.29108202e+00, ...,\n",
       "         -4.79816198e-01,  6.42109215e-01, -7.38214552e-02],\n",
       "        [-1.42837846e+00, -1.08723402e+00,  5.21048784e-01, ...,\n",
       "         -1.17819118e+00, -7.65655875e-01, -1.23974943e+00],\n",
       "        [ 3.55558753e-01, -1.95017189e-01,  2.79479916e-03, ...,\n",
       "         -1.64987302e+00, -1.46050167e+00, -2.64529347e-01]]),\n",
       " '_n_support': array([4836, 4756, 3182], dtype=int32),\n",
       " 'dual_coef_': array([[ 5.00000000e+00,  5.00000000e+00,  1.29098466e+00, ...,\n",
       "         -5.32021985e-01, -5.00000000e+00, -5.00000000e+00],\n",
       "        [ 3.65454369e+00,  0.00000000e+00,  1.10435515e+00, ...,\n",
       "         -1.60335992e-03, -0.00000000e+00, -5.00000000e+00]]),\n",
       " 'intercept_': array([ 0.24245129,  0.25223554, -0.05259923]),\n",
       " '_probA': array([], dtype=float64),\n",
       " '_probB': array([], dtype=float64),\n",
       " 'fit_status_': 0,\n",
       " 'shape_fit_': (14450, 40),\n",
       " '_intercept_': array([ 0.24245129,  0.25223554, -0.05259923]),\n",
       " '_dual_coef_': array([[ 5.00000000e+00,  5.00000000e+00,  1.29098466e+00, ...,\n",
       "         -5.32021985e-01, -5.00000000e+00, -5.00000000e+00],\n",
       "        [ 3.65454369e+00,  0.00000000e+00,  1.10435515e+00, ...,\n",
       "         -1.60335992e-03, -0.00000000e+00, -5.00000000e+00]]),\n",
       " 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5ba9f5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "test_happy_pred = svc_model.predict(test_happy)\n",
    "print(test_happy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "109a3dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-138.25993      47.83075      12.43015       9.442147      2.8886764\n",
      "    9.218459     -1.7010719     5.866592     -1.1854713     1.8068024\n",
      "   -5.1761727    -2.8015115    -8.815862     -2.103603     -3.1512337\n",
      "    0.73841155   -7.360411      0.8245869     0.57170105    3.441814\n",
      "    0.19264491    2.0323708     0.3843471     1.3737916    -0.93068755\n",
      "    0.9424493     1.0967329     0.47656903   -0.8584002    -1.6949978\n",
      "   -0.619295      0.5549292    -1.308152      1.3822969    -1.8309324\n",
      "    0.40982783   -2.3747313    -1.2822636     1.3139466     0.30254412]\n",
      "[[ 0.68894565 -1.3008703   1.1330906  -0.62594897  0.83384556  1.5823922\n",
      "   0.75391036  1.6949327   0.40254703  0.93477666 -0.4041584  -0.28442252\n",
      "  -1.4825854  -0.4049933   0.198373    0.6424882  -1.5469548   0.87359196\n",
      "   1.3397962   1.6784688   1.1318214   1.353408    0.9849124   0.9691251\n",
      "   0.3612777   0.6840961   1.0443158   0.45697284  0.04656575 -0.59102887\n",
      "   0.09626771  0.32925007 -0.29649228  0.686594   -0.6190391   0.27876273\n",
      "  -0.96122366 -0.5819204   1.1638557   0.37958565]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test_negative, _ = \\\n",
    "    extract_audio_features_mean(\"../../angry.wav\", len_secs=3,\n",
    "                                  n_mfccs=40, rms=False, zrc=False)\n",
    "print(test_negative)\n",
    "test_negative = svc_model.scaler.transform(test_negative.reshape(1, -1))\n",
    "print(test_negative)\n",
    "test_negative_pred = svc_model.predict(test_negative)\n",
    "print(test_negative_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8237eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-190.24722      46.390522     18.75701      27.056196      5.0892696\n",
      "   15.369224     -0.8989706    11.484544     -2.2059097     2.6998034\n",
      "   -4.582983     -1.2573931    -4.801177      4.4592733    -1.8320419\n",
      "    5.2400537    -1.6288586     1.4911369     3.028813      2.1564338\n",
      "   -4.174566      1.2735795    -2.1502934    -0.76275975   -1.222827\n",
      "    1.1108754    -1.8192449    -0.49994603   -0.6435079    -0.27612004\n",
      "   -0.24331577    2.4745038    -2.229893      0.8968766    -0.39293244\n",
      "    0.2933206    -1.1387155    -2.3547163     1.1650361    -0.72762954]\n",
      "[[-0.0923997  -1.3713318   1.5234146   0.91952837  1.0655512   2.3556042\n",
      "   0.86885124  2.5254362   0.21488565  1.1102118  -0.27108246  0.08979627\n",
      "  -0.49990383  1.278633    0.5586879   1.9928544   0.33144203  1.0924168\n",
      "   2.2198617   1.2273631  -0.49476242  1.0621066  -0.04043174  0.10946898\n",
      "   0.24574153  0.75516856 -0.14064033  0.04618806  0.13530299  0.02927476\n",
      "   0.26190558  1.1767861  -0.7280971   0.46574375  0.11481909  0.22162375\n",
      "  -0.2869724  -1.1706583   1.074463   -0.2603866 ]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "test_neutral, _ = \\\n",
    "    extract_audio_features_mean(\"../../neutral_2.wav\", len_secs=3,\n",
    "                                  n_mfccs=40, rms=False, zrc=False)\n",
    "print(test_neutral)\n",
    "test_neutral = scaler.transform(test_neutral.reshape(1, -1))\n",
    "print(test_neutral)\n",
    "test_neutral_pred = svc_model.predict(test_neutral)\n",
    "print(test_neutral_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b1799e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_1    -225.151460\n",
      "mfcc_2     109.085250\n",
      "mfcc_3     -27.196510\n",
      "mfcc_4      10.121292\n",
      "mfcc_5       1.344766\n",
      "mfcc_6     -12.285128\n",
      "mfcc_7     -18.956467\n",
      "mfcc_8     -10.092272\n",
      "mfcc_9     -12.402256\n",
      "mfcc_10     -5.953549\n",
      "mfcc_11     -6.343150\n",
      "mfcc_12     -9.125022\n",
      "mfcc_13     -3.000541\n",
      "mfcc_14     -6.843306\n",
      "mfcc_15     -3.434034\n",
      "mfcc_16     -2.889093\n",
      "mfcc_17     -4.126051\n",
      "mfcc_18     -3.769894\n",
      "mfcc_19     -1.705133\n",
      "mfcc_20     -6.406855\n",
      "mfcc_21     -5.169720\n",
      "mfcc_22     -1.708011\n",
      "mfcc_23     -4.280241\n",
      "mfcc_24     -3.766256\n",
      "mfcc_25     -4.359924\n",
      "mfcc_26     -2.121166\n",
      "mfcc_27     -3.779163\n",
      "mfcc_28     -3.300152\n",
      "mfcc_29     -3.509409\n",
      "mfcc_30     -2.014054\n",
      "mfcc_31     -2.784825\n",
      "mfcc_32     -2.542096\n",
      "mfcc_33     -1.216293\n",
      "mfcc_34     -1.769727\n",
      "mfcc_35     -0.876318\n",
      "mfcc_36     -1.842804\n",
      "mfcc_37     -1.077330\n",
      "mfcc_38     -0.488476\n",
      "mfcc_39     -0.340661\n",
      "mfcc_40     -0.298670\n",
      "Name: 20LfN8ENbhM_6, dtype: float64\n",
      "(array([-195.52985   ,   92.70075   ,  -24.008392  ,   10.492144  ,\n",
      "         -6.4965787 ,  -18.499443  ,  -17.859005  ,  -13.474919  ,\n",
      "         -8.963863  ,   -7.732952  ,   -9.457983  ,   -3.5309544 ,\n",
      "         -7.2717237 ,   -3.894504  ,   -4.5399246 ,   -6.592246  ,\n",
      "         -1.472745  ,   -6.1299205 ,   -6.881275  ,   -2.304553  ,\n",
      "         -5.336194  ,   -4.8850164 ,   -4.1405487 ,   -3.3099942 ,\n",
      "         -3.8576074 ,   -4.1142683 ,   -2.4667516 ,   -2.9003258 ,\n",
      "         -3.1817105 ,   -1.2571107 ,   -2.089558  ,   -1.6431712 ,\n",
      "         -2.0988235 ,   -1.2071482 ,   -0.34366733,   -0.29154432,\n",
      "         -0.20354536,   -0.28135467,    0.36818227,    0.25190628],\n",
      "      dtype=float32), ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19', 'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25', 'mfcc_26', 'mfcc_27', 'mfcc_28', 'mfcc_29', 'mfcc_30', 'mfcc_31', 'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'mfcc_37', 'mfcc_38', 'mfcc_39', 'mfcc_40'])\n"
     ]
    }
   ],
   "source": [
    "test_feats = mfcc40_3sec_median.loc['20LfN8ENbhM_6']\n",
    "test_featsu = \\\n",
    "    extract_audio_features_median(f\"{audio_out_dir}/20LfN8ENbhM_6.wav\", len_secs=3,\n",
    "                                  n_mfccs=40, rms=False, zrc=False)\n",
    "\n",
    "print(test_feats)\n",
    "print(test_featsu)\n",
    "# test_feats = scaler.transform(test_feats.values.reshape(1, -1))\n",
    "# test_pred = svc_model.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3d6fb334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "851f9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['261267_19']\n"
     ]
    }
   ],
   "source": [
    "rand_negative = \\\n",
    "    np.random.choice(\n",
    "        sentiment_labels[sentiment_labels['negative'] == 1].index.tolist(),\n",
    "        1)\n",
    "print(rand_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a876b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = mfcc40_3sec_median.loc['20LfN8ENbhM_6']\n",
    "# print(test_feats)\n",
    "test_feats = scaler.transform(test_feats.values.reshape(1, -1))\n",
    "test_pred = svc_model.predict(test_feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
